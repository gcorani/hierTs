z2 <- (lcl - mu1) / (sigma / sqrt(n))
beta = pnorm(z1) - pnorm(z2)
arl = 1/(1-beta)
ucl
lcl
beta
arl
8.91 / 2.97
2.26/5
3/5
2*2.26/5
n <- 9
sigma <- 3
mu <- 52
z1 <- (56 - mu) / (sigma / sqrt(n))
z2 <- (50 - mu) / (sigma / sqrt(n))
z1
z2
p <- .15
p + 3 * sqrt (p * (1-p) /75)
0.0369 / (6 * 0.738)
(6 * 0.738) / 0.0369
1/.6
2.574 * 2.41
2.574 * 2.14
# SES ---------------------------------------------------------------------
y = c(5, 8, 9)
l = vector (length = length(y))
l[1] = 1
alpha <- 0.5
for (t in (1: (length(y)-1))) {
l[t+1] <- alpha * y[t] + (1-alpha) * l[t]
}
y
l
0.5 * 8 + 0.5 * 5* 0.5 + 0.5 ^2 *1
l
.9*(3.75-1.5)+.1*1.5
.9*(3.75-1.5)
source('~/switchDrive/paperReconc/code/draw_arima.R', echo=TRUE)
artificialTs(500000, correl = .5)
inverse = function (f, lower = -100, upper = 100) {
function (y) uniroot((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
phi<- c(0.5,0.5)
phi<- c(0.5,0.8)
#we assume everywhere noise with variance 1
sigmaB1 <- sqrt(1 - phi[1]^2)
sigmaB1
inverse = function (f, lower = -100, upper = 100) {
function (y) uniroot((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
correl_inverse = inverse(function (x) x^2 - sigmaB1, 0.1, 100)
correl_inverse(1)
sqrt(1.866)
?uniroot
phi
#determines the value of sigma12
sigma_12<- function (phi) {
#we assume everywhere noise with variance 1
sigmaB1 <- sqrt(1 - phi[1]^2)
inverse = function (f, lower = -100, upper = 100) {
function (y) uniroot((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
correl_inverse = inverse(function (x) x^2 - sigmaB1, 0.1, 100)
a = correl_inverse(1)
return(a)
}
#determines the value of sigma12
sigma_12<- function (phi) {
#we assume everywhere noise with variance 1
sigmaB1 <- sqrt(1 - phi[1]^2)
inverse = function (f, lower = -100, upper = 100) {
function (y) uniroot((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
correl_inverse = inverse(function (x) x^2 - sigmaB1, 0.1, 100)
a = correl_inverse(1)
return(a)
}
sigma_12(phi <- c(0.5, 0.8))
source('~/switchDrive/paperReconc/code/draw_arima.R')
#determines the value of sigma12
sigma_12<- function (phi) {
#we assume everywhere noise with variance 1
sigmaB1 <- 1/sqrt(1 - phi[1]^2)
a <- 1/(1-phi[1]^2)
b <- 1 - prod(phi)
c <- 1/(1-phi[1]^2) + 1/(1-phi[2]^2)
inverse = function (f, lower = -100, upper = 100) {
function (y) uniroot((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
correl_inverse = inverse(function (x) x^2 - sigmaB1, 0.1, 100)
a = correl_inverse(1)
return(a)
}
source('~/switchDrive/paperReconc/code/draw_arima.R')
#determines the value of sigma12
get_rho12<- function (phi) {
#we assume everywhere noise with variance 1
inv_sigmaB1 <- sqrt(1 - phi[1]^2)
a <- 1/(1-phi[1]^2)
b <- 1 - prod(phi)
c <- 1/(1-phi[1]^2) + 1/(1-phi[2]^2)
inverse = function (f, lower = -100, upper = 100) {
function (y) uniroot((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
correl_inverse = inverse(function (x) inv_sigmaB1 * (a + x/(1-prod(phi))))
rho12 = correl_inverse(0.5)
return(rho12)
}
get_rho12(c(.5,.8))
source('~/switchDrive/paperReconc/code/draw_arima.R')
get_rho12(c(.5,.8))
source('~/switchDrive/paperReconc/code/draw_arima.R')
get_rho12(c(.5,.8), .5)
phi
#we use arma(2,2) only
# arOrders <- c(2,2)
# maOrders <- c(2,2) #(runif(2) > 0.5)  + 1
#the pars referring to the same  time series are in the same column: different columns refer to different models
arOrder <- 1
if (! howMany==2) {
stop("only two  bottom time series are supported")
}
phi <- runif(howMany)
phi <- c(0.5,0.8)
correl <-  -0.1381205
noise <- drawNoise(n, correl, howMany)
bottomTs <- simulVAR1(n, phi, noise)
upperTs <- rowSums(bottomTs)
hierarchy <- data.frame(cbind(bottomTs, upperTs))
colnames(hierarchy) <- c("b1","b2","u")
# debug
print ("phi:")
print(phi)
expectedVar_B1 <- 1/(1-phi[1]^2)
print("expected and empirical var of B1:")
print (c(expectedVar_B1, var(hierarchy[,1])))
expectedCovarB1B2 <- correl / (1 - prod(phi))
empiricalCovarB1B2 <- cov(hierarchy)[1,2]
print ("expected and empirical covar of B1 and B2:")
n
n <- 100000
noise <- drawNoise(n, correl, howMany)
howMany <- 2
noise <- drawNoise(n, correl, howMany)
bottomTs <- simulVAR1(n, phi, noise)
upperTs <- rowSums(bottomTs)
hierarchy <- data.frame(cbind(bottomTs, upperTs))
colnames(hierarchy) <- c("b1","b2","u")
# debug
print ("phi:")
print(phi)
expectedVar_B1 <- 1/(1-phi[1]^2)
print("expected and empirical var of B1:")
print (c(expectedVar_B1, var(hierarchy[,1])))
expectedCovarB1B2 <- correl / (1 - prod(phi))
empiricalCovarB1B2 <- cov(hierarchy)[1,2]
print ("expected and empirical covar of B1 and B2:")
print (c(expectedCovarB1B2, empiricalCovarB1B2))
print ("expected and empirical correl of B1 and B2:")
#we assume sigma^2=1, which disappears from below
expectedCorrelB1B2 = expectedCovarB1B2 * sqrt( (1-phi[1]^2) * (1-phi[2]^2) )
empiricalCorrelB1B2 = cor(hierarchy)[1,2]
print (c(expectedCorrelB1B2, empiricalCorrelB1B2))
print ("expected and empirical variance of U:")
#we assume sigma^2=1, which disappears from below
varBottom = 1 / (1 - phi^2)
expectedVar_U = varBottom[1] + varBottom[2] + 2 * expectedCorrelB1B2 *
sqrt(prod (varBottom))
expectedVar_U_second = varBottom[1] + varBottom[2] + 2 * correl /
(1-prod (phi))
empiricalVar_U = cov(hierarchy)[3,3]
print (c(expectedVar_U, expectedVar_U_second, empiricalVar_U))
print ("expected and empirical covariance (B1,U):")
expectedCovB1_U = 1/ (1-phi[1]^2) + correl/(1-prod(phi))
empiricalCovB1_U = cov(hierarchy)[1,3]
print (c(expectedCovB1_U, empiricalCovB1_U))
print ("expected and empirical correl of B1 and U:")
expectedCorB1_U =  expectedCovB1_U / sqrt  ( 1/(1-phi[1]^2) * expectedVar_U )
empiricalCorB1_U = cor(hierarchy)[1,3]
print (c(expectedCorB1_U, empiricalCorB1_U))
get_rho12(phi=c(0.5, 0.8), corB1_U = 0.5)
install.packages("rootSolve")
library("rootSolve", lib.loc="/Library/Frameworks/R.framework/Versions/3.5/Resources/library")
source('~/switchDrive/paperReconc/code/draw_arima.R')
get_rho12(phi=c(0.5, 0.8), corB1_U = 0.5)
source('~/switchDrive/paperReconc/code/draw_arima.R')
#determines the value of sigma12
get_rho12<- function (phi, corB1_U) {
#we assume everywhere noise with variance 1
inv_sigmaB1 <- sqrt(1 - phi[1]^2)
a <- 1/(1-phi[1]^2)
b <- 1 - prod(phi)
c <- 1/(1-phi[1]^2)
d <- 1/(1-phi[2]^2)
#range is +-1 becasue we are talking about a correlation
inverse = function (f, lower = -1, upper = 1) {
function (y) uniroot.all((function (x) f(x) - y), lower = lower, upper = upper)[1]
}
correl_inverse = inverse(function (x) inv_sigmaB1 * (a + x/(1-prod(phi))) *
1/(sqrt(c + d + 2 * x/b)) )
rho12 = correl_inverse(corB1_U)
return(rho12)
}
get_rho12(phi=c(0.5, 0.8), corB1_U = 0.5)
?uniroot.all
debugSource('~/switchDrive/paperReconc/code/draw_arima.R', echo=TRUE)
get_rho12(phi=c(0.5, 0.8), corB1_U = 0.5)
rho12
source('~/switchDrive/paperReconc/code/draw_arima.R', echo=TRUE)
source('~/switchDrive/paperReconc/hierTsCode/batchSynth.R', echo=TRUE)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
source("hierRec.R")
setwd("~/switchDrive/paperReconc/hierTsCode")
source("hierRec.R")
batchSynth(0.58,100)
source('~/switchDrive/paperReconc/hierTsCode/batchSynth.R', echo=TRUE)
batchSynth(0.58,100)
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R', echo=TRUE)
batchSynth(0.58,58)
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R', echo=TRUE)
batchSynth(0.58,58)
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R', echo=TRUE)
batchSynth(0.58,58)
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
batchSynth(0.58,58)
filenmae
filename
filename <- paste("results/mseHierReconc",dset,".csv",sep="")
filename
?paste
paste0("results/mseHierReconc",dset,".csv",sep="")
dset
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
#we need to load the same file in which hierRec has written the results
dset <- paste0("synthetic","_correl",correl,"_n",n)
filename <- paste0("results/mseHierReconc",dset,".csv",sep="")
filename
getwd()
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
batchSynth(0.58,58)
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
batchSynth(0.59,59)
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
debugSource('~/switchDrive/paperReconc/hierTsCode/batchSynth.R', echo=TRUE)
batchSynth(0.59,59)
source('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
batchSynth(0.59,59)
source('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
batchSynth(0.59,59)
source('~/switchDrive/paperReconc/hierTsCode/batchSynth.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec("synthetic", seed=1489, synth_n = 5, synthCorrel = 0.1)
hierRec("synthetic", seed=1490, synth_n = 5, synthCorrel = 0.1)
library(readr)
data <- read_csv("results/mseHierReconcsynthetic_correl0.1_n5.csv")
View(data)
data <- na.omit(data)
Sigma <- 5 * diag (bottomTs)
Sigma
bottomTs <- 4 #as in the paper
Sigma <- 5 * diag (bottomTs)
Sigma
Sigma <- 5 * diag (bottomTs) #cov matrix
Sigma <- matrix(data = c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4)
)
rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4))
Sigma <- matrix(data = rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4))
)
Sigma
Sigma <- matrix(data = rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4)),
nrow = 4,
ncol = 4
)
Sigma
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma))
sampleSize <- 1000
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma))
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma)
library(MASS)
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma)
noise
runif(4)
simulVAR1(10)
source('~/switchDrive/paperReconc/hierTsCode/drawLargeHierarchy.R', echo=TRUE)
simulFourBottom <- function(n){
library(MASS)
bottomTs <- 4
#draw pars
phi <- runif(bottomTs)
#draw noise
Sigma <- matrix(data = rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4)), nrow = 4,ncol = 4)
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma)
simul <- matrix( nrow = (n+1), ncol = bottomTs)
simul[1,] = rep(0,bottomTs)
c <- 1
for (t in 2:(n+1)){
for (ts in 1:howManyTs ){
simul[t,ts] <- c + phi[ts] * simul[t-1,ts] + noise[t,ts]
}
return (simul[-1,])
}
simulFourBottom(100)
simulFourBottom <- function(n){
library(MASS)
bottomTs <- 4
#draw pars
phi <- runif(bottomTs)
#draw noise
Sigma <- matrix(data = rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4)), nrow = 4,ncol = 4)
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma)
simul <- matrix( nrow = (n+1), ncol = bottomTs)
simul[1,] = rep(0,bottomTs)
c <- 1
for (t in 2:(n+1)){
for (ts in 1:bottomTs ){
simul[t,ts] <- c + phi[ts] * simul[t-1,ts] + noise[t,ts]
}
return (simul[-1,])
}
a <- simulFourBottom(100)
a
library(MASS)
bottomTs <- 4
#draw pars
phi <- runif(bottomTs)
phi
#draw noise
Sigma <- matrix(data = rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4)), nrow = 4,ncol = 4)
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma)
colMeans(noise)
cov(noise)
sampleSize
simul <- matrix( nrow = (n+1), ncol = bottomTs)
simul[1,] = rep(0,bottomTs)
c <- 1
for (t in 2:(n+1)){
for (ts in 1:bottomTs ){
simul[t,ts] <- c + phi[ts] * simul[t-1,ts] + noise[t,ts]
}
return (simul[-1,])
simul <- matrix( nrow = (n+1), ncol = bottomTs)
simul[1,] = rep(0,bottomTs)
c <- 1
for (t in 2:(n+1)){
for (ts in 1:bottomTs ){
simul[t,ts] <- c + phi[ts] * simul[t-1,ts] + noise[t,ts]
}
n <- 1000
library(MASS)
bottomTs <- 4
#draw pars
phi <- runif(bottomTs)
#draw noise
Sigma <- matrix(data = rbind(c(5,3,2,1),
c(3,4,2,1),
c(2,2,5,3),
c(1,1,3,4)), nrow = 4,ncol = 4)
noise <- mvrnorm(n=2*sampleSize, mu = c(0,0,0,0), Sigma= Sigma)
simul <- matrix( nrow = (n+1), ncol = bottomTs)
simul[1,] = rep(0,bottomTs)
c <- 1
for (t in 2:(n+1)){
for (ts in 1:bottomTs ){
simul[t,ts] <- c + phi[ts] * simul[t-1,ts] + noise[t,ts]
}
return (simul[-1,])
a<-simulFourBottom(1000)
a
library(fpp2)
autoplot(ts(simul[,1]))
autoplot(ts(simul[,2]))
autoplot(ts(simul[,3]))
autoplot(ts(simul[,4]))
a<-simulFourBottom(1000)
a
source('~/switchDrive/paperReconc/hierTsCode/drawLargeHierarchy.R', echo=TRUE)
a<-simulFourBottom(1000)
head(a)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source("drawSmallHierarchy.R")
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source("drawLargeHierarchy.R")
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source("drawLargeHierarchy.R")
#we generate the hierarchy with *four* bottom time series
synthTs <- simulFourBottom(n=synth_n)
synth_n <- 100000
#we generate the hierarchy with *four* bottom time series
synthTs <- simulFourBottom(n=synth_n)
y=ts(synthTs, frequency = 1)
hierTs <- hts(y, bnames = colnames(y))
library(hts)
hierTs <- hts(y, bnames = colnames(y))
hierTs
summary(hierTs)
?hts
hierTs <- hts(y, bnames = colnames(y), characters=c(1,1))
hierTs
summary(hierTs)
summary(hierTs
hjierTs
hierTs
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec(dset="syntheticLarge")
hierRec(dset="syntheticLarge", synth_n = 1000)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec(dset="syntheticLarge", synth_n = 1000)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec(dset="syntheticLarge", synth_n = 1000)
hierRec(dset="synthetic", synth_n = 100)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
setwd("/private/var/folders/tr/48q31n41473glpbhlkdzc1qh0000gp/T/hierTsCode")
hierRec(dset="synthetic", seed=1, synth_n = n, synthCorrel = correl)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
setwd("~/switchDrive/paperReconc/hierTsCode")
hierRec(dset="synthetic", seed=1, synth_n = n, synthCorrel = correl)
hierRec(dset="synthetic", seed=1, synth_n = 100, synthCorrel = 0.5)
hierRec(dset="synthetic", seed=2, synth_n = 100, synthCorrel = 0.5)
hierRec(dset="synthetic", seed=3, synth_n = 100, synthCorrel = 0.5)
synthCorrel = 0.5
synth_n = 100
dset <- paste0("synthetic","_correl",correl,"_n",n)
dset <- paste0("synthetic","_correl",synthCorrel,"_n",synth_n)
filename <- paste0("results/",dset,".csv",sep="")
currentData <- read_csv(filename)
library(readr)
currentData <- read_csv(filename)
currentData <- na.omit(currentData)
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
currentData$correlB1_U[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
median(currentData$mseCombMintShr/currentData$mseBayesGlasso)
)
currentData
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="synthetic", seed=3, synth_n = 100, synthCorrel = 0.5)
hierRec(dset="synthetic", seed=5, synth_n = 100, synthCorrel = 0.5)
dataFrame <- data.frame(h, fmethod, synth_n, synthCorrel, corrB2_U, mseBase,mseCombMintSample,
mseCombMintShr, mseBayesDiag, mseBayesSample, mseBayesGlasso)
h=1
hierRec(dset="synthetic", seed=5, synth_n = 100, synthCorrel = 0.5)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec(dset="synthetic", seed=5, synth_n = 100, synthCorrel = 0.5)
dataFrame
for (i in in 1:100) hierRec(dset="synthetic", seed=i, synth_n = 100, synthCorrel = 0.5)
for (i in (1:100)) hierRec(dset="synthetic", seed=i, synth_n = 100, synthCorrel = 0.5)
hierRec(dset="synthetic", seed=1, synth_n = 100, synthCorrel = 0.5)
mseBase
dset
dataFrame
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="sam")
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="shr")
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="synthetic", seed=1, synth_n = 100, synthCorrel = 0.5)
hierRec(dset="synthetic", seed=1, synth_n = 1000, synthCorrel = 0.5)
synthTs
synthCorrel
synth_n <- 10000
#we generate the hierarchy with two bottom time series
#training and the test
listSynth <- artificialTs(n=synth_n + h, correl = synthCorrel)
hierTs
hierTs[[1]
]
hierTs[[2]]
hierTs[[3]]
hierTs[[1]]
hierTs
hierTs[1:100]
hierTs[1:10]
hierTs$bts
a <- hierTs$bts
u <- rowSums(a)
cor (cbind(a,u))
hierRec(dset="synthetic", seed=1, synth_n = 100, synthCorrel = 0.01)
hierRec(dset="synthetic", seed=2, synth_n = 100, synthCorrel = 0.01)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="synthetic", seed=2, synth_n = 100, synthCorrel = 0.01)
dataFrame
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="sam")
