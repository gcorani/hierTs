source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = "CovLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = "CovUpperErrorsShr.pdf")
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = "CovUpperLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R', echo=TRUE)
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = "CovLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = "CovUpperErrorsShr.pdf")
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = "CovUpperLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
pdf(file = "ErrorsSam.pdf")
covError <- cov(residuals)
corError <- cov2cor(covError)
corrplot(corError, method = "circle", title = "residual correlation before shrinkage")
dev.off()
?corrplot
dset$labels
dset
dset$labels
shCov <-  shrink.estim(residuals, tar=build.target(residuals,type="D"))[[1]]
shCor <-  cov2cor(shCov)
colnames(shCor) <- infantgts$labels
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
colnames(shCor) <- infantgts$labels
infantgts$labels
infantgts
allTsTrain
colnames(allTsTrain)
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
pdf(file = "CovErrorsShr.pdf")
shCov <-  shrink.estim(residuals, tar=build.target(residuals,type="D"))[[1]]
shCor <-  cov2cor(shCov)
colnames(shCor) <- colnames(allTsTrain)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = "CovLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = "CovUpperErrorsShr.pdf")
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = "CovUpperLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
colnames(shCor) <- colnames(allTsTrain)
rownames(shCor) <- rownames(allTsTrain)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = "CovLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = "CovUpperErrorsShr.pdf")
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
colnames(shCor) <- colnames(allTsTrain)
rownames(shCor) <- colnames(allTsTrain)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = "CovLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = "CovUpperErrorsShr.pdf")
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = "CovUpperLowerErrorsShr.pdf")
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
dset
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = paste0(dset,"CovLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperErrorsShr.pdf"))
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
pdf(file = paste0(dset,"CovY.pdf"))
cor(actual)
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
pdf(file = paste0(dset,"CovY.pdf"))
corrplot(cor(actual), method = "circle", title = "Y correlations")
dev.off()
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
pdf(file = paste0(dset,"CovY.pdf"))
corY <- cor(actual)
colnames(corY) <- colnames(allTsTrain)
rownames(corY) <- colnames(allTsTrain)
corrplot(corY, method = "circle", title = "Y correlations")
dev.off()
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
dset<-"tourism"
h<-1
fmethod<-"ets"
iTest<-1
seed<-0
library(hts)
library(huge)#covariance matrix via glasso
library(SHIP)#shrinkage of covarianca matrix
source("loadTourism.R")
set.seed(seed)
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
if (iTest>possiblePreds){
stop("iTest>possiblePreds")
}
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#sometimes the sample matrix is not positive definite and minT crashes
#the matrix is computed internally by minT and cannot be controlled from here.
fcastCombMintShr <-
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="shr")
mseCombMintShr  <- hierMse(fcastCombMintShr, test,  h)
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
function (el, set)
match(el, set, 0L) > 0L
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
if (dset=="tourism"){
hierTs <- loadTourism()
}
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R', echo=TRUE)
if (dset=="tourism"){
hierTs <- loadTourism()
}
else if (dset=="infantgts"){
hierTs <- infantgts
}
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
if (iTest>possiblePreds){
stop("iTest>possiblePreds")
}
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#sometimes the sample matrix is not positive definite and minT crashes
#the matrix is computed internally by minT and cannot be controlled from here.
fcastCombMintShr <-
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="shr")
dset
a
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R', echo=TRUE)
library(hts)
library(huge)#covariance matrix via glasso
library(SHIP)#shrinkage of covarianca matrix
source("loadTourism.R")
set.seed(seed)
if (dset=="tourism"){
hierTs <- loadTourism()
}
else if (dset=="infantgts"){
hierTs <- infantgts
}
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
if (iTest>possiblePreds){
stop("iTest>possiblePreds")
}
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#sometimes the sample matrix is not positive definite and minT crashes
#the matrix is computed internally by minT and cannot be controlled from here.
fcastCombMintShr <-
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="shr")
mseCombMintShr  <- hierMse(fcastCombMintShr, test,  h)
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
#shrink to the diagonal
library(stats)
library(corrplot)
residuals
dim(residuals)
dset<-"tourism"
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R', echo=TRUE)
library(hts)
library(huge)#covariance matrix via glasso
library(SHIP)#shrinkage of covarianca matrix
source("loadTourism.R")
set.seed(seed)
if (dset=="tourism"){
hierTs <- loadTourism()
}
else if (dset=="infantgts"){
hierTs <- infantgts
}
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
h<-1
iTest<-1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#sometimes the sample matrix is not positive definite and minT crashes
#the matrix is computed internally by minT and cannot be controlled from here.
fcastCombMintShr <-
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="shr")
fmethod<-"ets"
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
residuals
dset
source("loadTourism.R")
set.seed(seed)
hierTs <- loadTourism()
hierTs
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
train
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
allTsTrain
train
allTsTrain[[1]]
allTsTrain[1,]
allTsTrain[,1]
allTsTrain[,2]
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
#shrink to the diagonal
library(stats)
library(corrplot)
pdf(file = "CovErrorsShr.pdf")
shCov <-  shrink.estim(residuals, tar=build.target(residuals,type="D"))[[1]]
shCor <-  cov2cor(shCov)
colnames(shCor) <- colnames(allTsTrain)
rownames(shCor) <- colnames(allTsTrain)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = paste0(dset,"CovLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperErrorsShr.pdf"))
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
pdf(file = paste0(dset,"CovY.pdf"))
corY <- cor(actual)
colnames(corY) <- colnames(allTsTrain)
rownames(corY) <- colnames(allTsTrain)
corrplot(corY, method = "circle", title = "Y correlations")
dev.off()
shCor[bottomIdx,upperIdx]
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
if (dset=="infantgts"){
colnames(shCor) <- colnames(allTsTrain)
rownames(shCor) <- colnames(allTsTrain)
}
shCov <-  shrink.estim(residuals, tar=build.target(residuals,type="D"))[[1]]
shCor <-  cov2cor(shCov)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = paste0(dset,"CovLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperErrorsShr.pdf"))
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
shCor[upperIdx,upperIdx]
summary(shCor[upperIdx,upperIdx])
summary(as.vector(shCor[upperIdx,upperIdx]))
summary(as.vector(shCor[upperIdx,bottomIdx]))
summary(as.vector(shCor[upperIdx,upper.tri()]))
summary(as.vector(shCor[upperIdx,upperIdx])
)
summary(as.vector(shCor[upperIdx,upperIdx]))
summary(as.vector(shCor[bottomIdx,bottomIdx]))
summary(as.vector(shCor[upperIdx,bottomIdx]))
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
.libPaths()
shrink.estimMINT <- function(x, tar)
{
if (is.matrix(x) == TRUE && is.numeric(x) == FALSE)
stop("The data matrix must be numeric!", call. = FALSE)
p <- ncol(x)
n <- nrow(x)
covm <- crossprod(x) / n
corm <- cov2cor(covm)
xs <- scale(x, center = FALSE, scale = sqrt(diag(covm)))
v <- (1/(n * (n - 1))) * (crossprod(xs^2) - 1/n * (crossprod(xs))^2)
diag(v) <- 0
corapn <- cov2cor(tar)
d <- (corm - corapn)^2
lambda <- sum(v)/sum(d)
lambda <- max(min(lambda, 1), 0)
shrink.cov <- lambda * tar + (1 - lambda) * covm
return(list(shrink.cov, c("The shrinkage intensity lambda is:",
round(lambda, digits = 4))))
}
shrink.estim()
library(SHIP)
?shrink.estim
x <- matrix(rnorm(20*30),20,30)
shrink.estim(x,tar=build.target(x,type="D"))
a<-shrink.estim(x,tar=build.target(x,type="D"))
b<-shrink.estimMINT(x,tar=build.target(x,type="D"))
b
b[[2]]
a[[2]]
x
b<-shrink.estimMINT(x,tar=build.target(x,type="D"))
a<-shrink.estim(x,tar=build.target(x,type="D"))
a
b
x <- matrix(rnorm(3*30),3,30)
a<-shrink.estim(x,tar=build.target(x,type="D"))
b<-shrink.estimMINT(x,tar=build.target(x,type="D"))
a
b
trace("minT", edit=TRUE)
trace("hts", edit=TRUE)
trace("forecast", edit=TRUE)
library(hts)
trace("forecast", edit=TRUE)
trace("minT", edit=TRUE)
trace(hts::forecast.gts, edit=TRUE)
library(Matrix)
