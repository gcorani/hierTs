hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
library(readr)
# reps <- 2500
reps <- 20
n=120
reps < - 10
reps <- 10
for (i in 1:reps){
hierRec(dset="syntheticLarge", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/",dset,".csv",sep="")
library(readr)
mse_largeSynthetic_n120 <- read_csv("results/mse_largeSynthetic_n120.csv")
View(mse_largeSynthetic_n120)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
library(readr)
mse_largeSynthetic_n120 <- read_csv("results/mse_largeSynthetic_n120.csv")
View(mse_largeSynthetic_n120)
currentData <- mse_largeSynthetic_n120
currentData
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
dataFrame
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=1)
hierRec("syntheticLarge", synth_n = 110, seed=2)
hierRec("syntheticLarge", synth_n = 110, seed=3)
hierRec("syntheticLarge", synth_n = 110, seed=4)
source('~/switchDrive/paperReconc/hierTsCode/batchLargeSynth.R')
reps <- 5
n = 25
reps <- 5
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData <- na.omit(currentData)
currentData
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
dataFrame
source('~/switchDrive/paperReconc/hierTsCode/batchLargeSynth.R')
colnames(dataFrame) <- c("fmethod", "sampleSize",  "mintSample/BayesSample",
"MintShr/BayesShr", "BayesShr/Base")
filename <- "results/summaryLargeSynthetic.csv"
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
dataFrame
library(readr)
reps <- 5
n <- 10
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData <- na.omit(currentData)
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
currentData
currentData$h
currentData$fmethod
currentData
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData
n <- 100
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData
currentData <- na.omit(currentData)
currentData
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
colnames(dataFrame) <- c("fmethod", "sampleSize",  "mintSample/BayesSample",
"MintShr/BayesShr", "BayesShr/Base")
filename <- "results/summaryLargeSynthetic.csv"
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
write.table(dataFrame, file=filename, append = TRUE, sep=",", row.names = FALSE, col.names = writeNames)
?visitors
library(fpp2)
?visitors
nsdiffs(visitors)
ndiffs( diff(visitors, lag=12))
autoplot(visitors, lag=12)
autoplot(diff(visitors, lag=12))
autoplot(diff(diff(visitors, lag=12)))
library(fpp2)
fit <- auto.arima(internet)
fit
?auto.arima
fit <- auto.arima(internet, start.p = 3)
fit
fit <- auto.arima(internet, stepwise=FALSE)
fit
library(fpp2)
autoplot(visitors)
nsdiffs(visitors)
nsdiffs( log (visitors))
nsdiffs( visitors)
autoplot(diff(visitors, lag=12))
ndiffs(diff(visitors, lag=12))
autoplot(ausbeer)
nsdiffs(ausbeer)
?ausbeer
autoplot( diff (ausbeer, lag=4 ))
ndiffs( diff (ausbeer, lag=4 ))
autoplot diff(( diff (ausbeer, lag=4 )))
autoplot (diff(( diff (ausbeer, lag=4 ))))
autoplot(rice)
autoplot(guinearice)
fit <- auto.arima(guinearice)
fit
autoplot( forecast(fit))
autoplot(internet)
?internet
autoplot(internet)
fit <- auto.arima(internet)
fit
autoplot(diff(internet))
library(fpp2)
?autolayer
sourc
#create figure of forecasts for the paper
source("hierRec.R")
library(hts)
library(SHIP)
set.seed(seed)
source("drawLargeHierarchy.R")
fmethod <- "arima"
synth_n <- 20
#we generate the hierarchy with *four* bottom time series
synthTs <- simulFourBottom(n=synth_n)
y=ts(synthTs, frequency = 1)
hierTs <- hts(y, bnames = colnames(y), characters=c(1,1))
maxH = 4
iTest <- 1
timeIdx <- time(hierTs$bts[,1])
startTrain          <- timeIdx[1]
endTrain            <- length(timeIdx) - maxH - (iTest - 1)
train               <- window(hierTs, start = startTrain, end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain +   maxH])
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
base <- matrix(ncol=numTs, nrow=maxH)
reconcBayes <- matrix(ncol=numTs, nrow=maxH)
for (h in (seq(1:maxH))){
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
}
#create figure of forecasts for the paper
source("hierRec.R")
library(hts)
library(SHIP)
set.seed(seed)
source("drawLargeHierarchy.R")
fmethod <- "arima"
synth_n <- 20
#we generate the hierarchy with *four* bottom time series
synthTs <- simulFourBottom(n=synth_n)
y=ts(synthTs, frequency = 1)
hierTs <- hts(y, bnames = colnames(y), characters=c(1,1))
maxH = 4
iTest <- 1
timeIdx <- time(hierTs$bts[,1])
startTrain          <- timeIdx[1]
endTrain            <- length(timeIdx) - maxH - (iTest - 1)
train               <- window(hierTs, start = startTrain, end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain +   maxH])
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
base <- matrix(ncol=numTs, nrow=maxH)
reconcBayes <- matrix(ncol=numTs, nrow=maxH)
for (h in (seq(1:maxH))){
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
}
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source('~/switchDrive/paperReconc/hierTsCode/figureFcast.R')
for (h in (seq(1:maxH))){
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
}
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
bayesRecon <- function (covariance){
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
Y_vec <- preds[upperIdx]
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
bottomResiduals <- residuals[,bottomIdx]
if (covariance=="diagonal"){
priorCov <- diag(bottomVar)
}
else if (covariance=="sam"){
#the covariances are the covariances of the time series
#the variances are the variances of the forecasts, hence the variances of the residuals
priorCov <- cov(bottomResiduals)
}
else if (covariance=="glasso"){
#the covariances are the covariances of the time series
#the variances are the variances of the forecasts, hence the variances of the residuals
out.glasso <- huge(bottomResiduals, method = "glasso", cov.output = TRUE)
out.select <- huge.select(out.glasso, criterion = "ebic")
priorCov <- out.select$opt.cov
}
else if (covariance=="shr"){
sigmaDiag <- diag(bottomVar)
priorCov <-  shrink.estim(bottomResiduals, tar=build.target(bottomResiduals,type="D"))[[1]]
}
upperVar <- sigma[upperIdx]^2
#covariance for the upper time series; we need managing separately the case where only a single time series is present
#as diag will try to create a matrix of size upperVar instead.
upperResiduals <- residuals[,upperIdx]
if (length(upperIdx)==1) {
Sigma_y <- upperVar
}
else if (covariance=="diagonal"){
Sigma_y <- diag(upperVar)
}
#if we only one upper time series, there is no covariance matrix to be estimated.
else if (covariance=="glasso") {
#get variance and covariance of the residuals
out.glasso <- huge(upperResiduals, method = "glasso", cov.output = TRUE)
out.select <- huge.select(out.glasso, criterion = "ebic")
Sigma_y <- out.select$opt.cov
}
else if (covariance=="sam") {
#get variance and covariance of the residuals
Sigma_y <- cov(upperResiduals)
}
else if (covariance=="shr") {
sigma_y_diag <- diag(upperVar)
Sigma_y <-  shrink.estim(upperResiduals, tar=build.target(upperResiduals,type="D"))[[1]]
}
#==updating
#A explains how to combin the bottom series in order to obtain the
# upper series
#if upperIdx contains a single row, R behaves oddily; hence we need to manually manage that case.
if (length(upperIdx)==1){
A <- cbind(S[upperIdx,])
}
else {
A <- t(S[upperIdx,])
}
M <- ncol ( t(A) %*% priorCov %*% A + Sigma_y )
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y + 1e-6*diag(M))
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
return(bayesPreds)
}
library(hts)
library(SHIP)
set.seed(seed)
source("drawLargeHierarchy.R")
fmethod <- "arima"
synth_n <- 20
#we generate the hierarchy with *four* bottom time series
synthTs <- simulFourBottom(n=synth_n)
y=ts(synthTs, frequency = 1)
hierTs <- hts(y, bnames = colnames(y), characters=c(1,1))
maxH = 4
iTest <- 1
timeIdx <- time(hierTs$bts[,1])
startTrain          <- timeIdx[1]
endTrain            <- length(timeIdx) - maxH - (iTest - 1)
train               <- window(hierTs, start = startTrain, end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain +   maxH])
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
base <- matrix(ncol=numTs, nrow=maxH)
reconcBayes <- matrix(ncol=numTs, nrow=maxH)
for (h in (seq(1:maxH))){
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
}
base <- matrix(ncol=numTs, nrow=maxH)
reconcBayes <- matrix(ncol=numTs, nrow=maxH)
for (h in (seq(1:maxH))){
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
}
h
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
buReconcile <- function (preds,S, predsAllTs = FALSE) {
bottomPreds <- preds
if (predsAllTs) {
#retrieves the bottom prediction from all predictions
upperIdx <- 1 : (nrow(S) - ncol(S))
bottomIdx <- setdiff (1:nrow(S), upperIdx)
bottomPreds <- preds [,bottomIdx]
}
buPreds <- preds
#nrow(S) is the total number of time series
for (i in 1:nrow(S)){
buPreds[i] <- S[i,] %*% bottomPreds
}
return (buPreds)
}
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
for (h in (seq(1:maxH))){
for (i in 1:numTs){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals
preds[i] <- tmp$mean[h]
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
reconcBayes[h,] <- bayesRecon(covariance="shr")
mseBayesShr =  mean   (allts(test)[h,] - reconcBayes[h,])^2
base[h,] <- preds
actual <- allts(test)
}
bottomIdx <- 1
actual <- hierTs$bts[,bottomIdx]
base   <- ts(base[,3+bottomIdx], start=timeIdx[endTrain +1])
reconc <- ts(reconcBayes[,3+bottomIdx], start=timeIdx[endTrain +1])
p <- autoplot(actual) + autolayer(base)   + autolayer(reconc) # + theme(legend.position = c(.95, .95))
p
p <- autoplot(actual) + autolayer(base)   + autolayer(reconc, flwd = 0.5) # + theme(legend.position = c(.95, .95))
p <- autoplot(actual, flwd=2) + autolayer(base)   + autolayer(reconc, flwd = 0.5)
p <- autoplot(actual, flwd=2)
dev.off()
p <- autoplot(actual, flwd=2)
actual
p <- autoplot(actual)
dev.off()
p <- autoplot(actual)
p
p <- autoplot(actual,flwd = 0.5)
p
p <- autoplot(actual,flwd = 5)
p
p <- forecast::autoplot(actual,flwd = 5)
p
p <- forecast::autoplot(actual,flwd = 0.5)
p
p <- forecast::autoplot(actual, size = 0.5)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base)   + autolayer(reconc, flwd = 0.5)
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base)   + autolayer(reconc, size = 0.5)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base)   + autolayer(reconc, size = 2)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1,  ts.linetype = 'dashed')   + autolayer(reconc, size = 1)
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 'dashed')   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 1)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 2)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 3)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 4)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 5)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1, linetype = 6)   + autolayer(reconc, size = 1)
p
p <- forecast::autoplot(actual, size = 0.5) + autolayer(base, size = 1)   + autolayer(reconc, size = 1)
p
