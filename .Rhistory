#Sets correctly the columns names currently not possible
maeHts <- abs (allts(htsPred) - allts(htsActual))[h,]
# colnames(maeHts) <- colnames(allts(htsPred))
return (maeHts)
}
hierMse <- function (htsPred, htsActual) {
#receives two hts objects, containing  forecast and actual value.
#computes the mse for the whole hierarchy.
mse <- mean  ( ((allts(htsPred) - allts(htsActual))[h,])^2 )
return (mse)
}
#extract the time from the data set to then split into train / test (test set contains 25 or 5 time points)
set.seed(seed = 0)
dset="tourism"
h=1
if (dset=="tourism"){
hierTs <- loadTourism()
}
testSize <- 25
if (length(hierTs$bts[,1]) < 25){
testSize <- 5
}
if (dset=="tourism"){
hierTs <- loadTourism()
}
testSize <- 25
if (length(hierTs$bts[,1]) < 25){
testSize <- 5
}
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
possiblePreds
totTs       <- nrow(smatrix(hierTs))
maeBu       <- matrix(nrow = possiblePreds, ncol = totTs)
maeComb     <- matrix(nrow = possiblePreds, ncol = totTs)
maeCombWls  <- matrix(nrow = possiblePreds, ncol = totTs)
maeCombMint <- matrix(nrow = possiblePreds, ncol = totTs)
maeBayes    <- matrix(nrow = possiblePreds, ncol = totTs)
#These vectors will contain the global mse, summed over all the time series of the hierarchy
mseBu       <- vector(length   = possiblePreds)
mseComb     <- vector(length   = possiblePreds)
mseCombWls  <- vector(length   = possiblePreds)
mseCombMint <- vector(length   = possiblePreds)
mseBayes    <- vector(length   = possiblePreds)
possiblePreds<-2
fmethod<-"ets"
for (iTest in 1:possiblePreds) {
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMint       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod)
maeBu[iTest,]       <- hierMae(fcastBu, test )
maeComb[iTest,]     <- hierMae(fcastComb, test )
maeCombWls[iTest,]  <- hierMae(fcastCombWls, test )
maeCombMint[iTest,] <- hierMae(fcastCombMint, test )
mseBu[iTest]        <- hierMse(fcastBu, test )
mseComb[iTest]      <- hierMse(fcastComb, test )
mseCombWls[iTest]   <- hierMse(fcastCombWls, test )
mseCombMint[iTest]  <- hierMse(fcastCombMint, test )
#recompute predictions to be easily accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(ts(allTsTrain[,i]), additive.only = TRUE)
tmp <- forecast(model, h=h, level=1-alpha)
}
else if (fmethod=="arima"){
model <- auto.arima(ts(allTsTrain[,i]))
tmp <- forecast(model, h=h, level=1-alpha)
}
preds[i] <- tmp$mean[h]
sigma[i] <- abs ( (tmp$mean[h] - tmp$upper[h])  / (qnorm(alpha / 2)) )
}
S <- smatrix(train)
#Bayesian reconciliation
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
#prior mean and covariance of the upper time series
Y_vec <- preds[upperIdx]
Sigma_y <- matrix(nrow = length(upperIdx), ncol = length(upperIdx))
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
priorCov <- diag(bottomVar)
#covariance for the upper time series
upperVar <- sigma[upperIdx]^2
Sigma_y <- diag(upperVar)
#==update in a single shot
#A explains how to combin the bottom series in order to obtain the
# upper series
A <- t(S[upperIdx,])
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y)
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
maeBayes[iTest,] = abs (allts(test)[h,] - bayesPreds)
mseBayes[iTest] = mse <- mean  ( (allts(test)[h,] - bayesPreds)^2 )
}
sum(abs(allts(test)[4,] - bayesPreds))
sum(abs(allts(test)[1,] - bayesPreds))
sum(allts(test)[1,])
sum(allts(test)[2,])
test
test[[1]]
dim(test[[1]])
dim(test[[1,]])
train
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
dsert
dset
h
train
library(hts)
source("loadTourism.R")
if (is.character(dset) == FALSE) {
stop ("dset should be a string")
}
#The buReconcile function computes the bu prediction given the predictions (1 x tot time series) and the S matrix
#(tot time series X bottom time series)
#predsAllTs is a flag: is set to true, the input preds contains predictions for all the hierarchy
#and the function retrieves the bottom series; if set to false, this is not needed
#as preds only contains only bottom time series
buReconcile <- function (preds,S, predsAllTs = FALSE) {
bottomPreds <- preds
if (predsAllTs) {
#retrieves the bottom prediction from all predictions
upperIdx <- 1 : (nrow(S) - ncol(S))
bottomIdx <- setdiff (1:nrow(S), upperIdx)
bottomPreds <- preds [,bottomIdx]
}
buPreds <- preds
#nrow(S) is the total number of time series
for (i in 1:nrow(S)){
buPreds[i] <- S[i,] %*% bottomPreds
}
return (buPreds)
}
hierMae <- function (htsPred, htsActual) {
#receives two hts objects, containing  forecast and actual value.
#computes the mae for the relevant forecast horizon only
#Sets correctly the columns names currently not possible
maeHts <- abs (allts(htsPred) - allts(htsActual))[h,]
# colnames(maeHts) <- colnames(allts(htsPred))
return (maeHts)
}
hierMse <- function (htsPred, htsActual) {
#receives two hts objects, containing  forecast and actual value.
#computes the mse for the whole hierarchy.
mse <- mean  ( ((allts(htsPred) - allts(htsActual))[h,])^2 )
return (mse)
}
#extract the time from the data set to then split into train / test (test set contains 25 or 5 time points)
set.seed(seed = 0)
dset
if (dset=="tourism"){
hierTs <- loadTourism()
}
testSize <- 25
if (length(hierTs$bts[,1]) < 25){
testSize <- 5
}
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
totTs       <- nrow(smatrix(hierTs))
maeBu       <- matrix(nrow = possiblePreds, ncol = totTs)
maeComb     <- matrix(nrow = possiblePreds, ncol = totTs)
maeCombWls  <- matrix(nrow = possiblePreds, ncol = totTs)
maeCombMint <- matrix(nrow = possiblePreds, ncol = totTs)
maeBayes    <- matrix(nrow = possiblePreds, ncol = totTs)
#These vectors will contain the global mse, summed over all the time series of the hierarchy
mseBu       <- vector(length   = possiblePreds)
mseComb     <- vector(length   = possiblePreds)
mseCombWls  <- vector(length   = possiblePreds)
mseCombMint <- vector(length   = possiblePreds)
mseBayes    <- vector(length   = possiblePreds)
testSize
possiblePreds
iTest
iTest <- 1
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
endTrain
train
iTest<-1
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
train
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastBu
fcastBu[[1]]
library(readr)
temporalHier_monthly_ets <- read_csv("temporalHier_monthly_ets.csv")
View(temporalHier_monthly_ets)
boxplot( (a$mseBase - a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
a <- temporalHier_monthly_ets
boxplot( (a$mseBase - a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
abline(0,0)
boxplot( (a$mseBu - a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
abline(0,0)
boxplot( (a$mseThief- a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
abline(0,0)
library(readr)
b <- read_csv("temporalHier_weekly_arima.csv")
View(temporalHier_weekly_arima)
a<-b
boxplot( (a$mseThief- a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
abline(0,0)
boxplot( (a$mseBase- a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
library(readr)
temporalHier_quarterly_ets <- read_csv("temporalHier_quarterly_ets.csv")
View(temporalHier_quarterly_ets)
library(readr)
temporalHier_quarterly_ets <- read_csv("temporalHier_quarterly_ets.csv")
a< -temporalHier_quarterly_ets
a<- temporalHier_quarterly_ets
boxplot( (a$mseBase- a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
boxplot( (a$mseThief- a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
boxplot( (a$mseBu - a$mseBayes)/(( a$mseBase + a$mseBayes + a$mseBu + a$mseThief) /4) )
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
htseg1
?hts
?randu
randu(5)
?rand
?ru
?runif
runif(5)
?arima
?crossprod
crossprod(c(1,2),c(3,4))
order=5
alpha <- runif(order)
ts <- vector(length = n + order)
n<-1000
ts <- vector(length = n + order)
ts[1:order] <- runif(order)
ts
i<- 6
ts[(i-order):(i-1)]
ts[i] <- crossprod(ts[(i-order):(i-1)], alpha )
t
for (i in (order+1):(order+n)){
ts[i] <- crossprod(ts[(i-order):(i-1)], alpha )
}
ts
autoplot(ts)
plot(ts)
/root
root
?root
??root
polyroot(alpha)
polyroot(rbind(-1,-alpha))
roots <- polyroot(rbind(-1,-0.5))
roots
roots <- polyroot(rbind(-1,-2))
roots
#check that alpha is stable
#get the implied roots
roots <- polyroot(rbind(-1,-alpha))
class(roots)
roots
abs(roots)
abs(roots)<1
unstable <- TRUE
alpha <- runif(order)
#check that alpha is stable
#get the implied roots
roots <- polyroot(rbind(-1,-alpha))
check <- abs(roots)>1
if mean(check==1){
unstable <- FALSE
}
check
mean(check)==1
unstable <- TRUE
while (unstable){
alpha <- runif(order)
#check that alpha is stable
#get the implied roots
roots <- polyroot(rbind(-1,-alpha))
check <- abs(roots)>1
if mean(check)==1 {
unstable <- FALSE
}
alpha
ts <- vector(length = n + order)
ts[1:order] <- runif(order)
for (i in (order+1):(order+n)){
ts[i] <- crossprod(ts[(i-order):(i-1)], alpha )
}
plot(ts)
unstable <- TRUE
while (unstable){
alpha <- runif(order)
#check that alpha is stable
#get the implied roots
roots <- polyroot(rbind(-1,-alpha))
check <- abs(roots)>1
if mean(check)==1 {
unstable <- FALSE
}
roots
abs(roots)
check
unstable <- TRUE
while (unstable){
alpha <- runif(order)
#check that alpha is stable
#get the implied roots
roots <- polyroot(rbind(-1,-alpha))
check <- abs(roots)>1
if (mean(check)==1) {
unstable <- FALSE
}
alpha
ts <- vector(length = n + order)
ts[1:order] <- runif(order)
for (i in (order+1):(order+n)){
ts[i] <- crossprod(ts[(i-order):(i-1)], alpha )
}
plot(ts)
roots
check
abs(roots)
?tsCV
library(fpp2)
?tsCV
far2 <- function(x, h)
{forecast(auto.arima, h=h)}
e <- tsCV(lynx, far2, h=1)
e
far2 <- function(x, h){forecast(Arima(x, order=c(2,0,0)), h=h)}
e <- tsCV(lynx, far2, h=1)
e
farima <- function(x, h) {
forecast(auto.arima(x),h=h)
}
e <- tsCV(lynx, farima, h=1)
htseg1
library(hts)
htseg2[[1]]
htseg2[[1]][,1]
library(fpp2)
library(hts)
farima <- function(x, h) {
forecast(auto.arima(x),h=h)
}
1:dim(htseg2[[1]][2])
dim(htseg2[[1]][2])
dim(htseg2[[1]])
dim(htseg2[[1]])1:dim(htseg2[[1]])[2]
1:dim(htseg2[[1]])[2]
i <- 1
e <- tsCV(ts, farima, h=1)
fets <- function(x, h) {
forecast(ets(x), h = h)
}
i
ts <- htseg2[[1]][,i]
ts
e <- tsCV(ts, fets, h=1)
model <- ets(ts)
sd(e)
sd(e, na.rm = TRUE)
forecast(model,h=1)
-1.21321 - -1.356712
-1.21321  -1.356712
-2.569922 / 1.96
e
model$residuals
sd(model$residuals)
sd(e, na.rm = TRUE)
forecast(model,h=1, level = 95)
-1.21321 + -1.356712
(-1.21321  -1.356712)
(-1.21321  1.356712)
(-1.21321 +  1.356712)
(-1.21321  1.356712) / 1.96
(-1.21321  +  1.356712) / 1.96
a<-1
a==1
a!=1
hier(htseg1)
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier(htseg1)
hier("htseg1")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier("htseg1")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier("htseg1")
hier("htseg1", cv = TRUE)
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier("htseg1", cv = TRUE)
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier("htseg1", cv = TRUE)
sigma[i]
abs ( (tmp$mean[h] - tmp$upper[h])  / (qnorm(alpha / 2)) )
sigma[i]
i
sigma[1]
hier("htseg1", cv = TRUE)
hier("htseg1", h=2)
hier("htseg1", h=2, cv = TRUE)
hier("htseg2", h=1)
hier("htseg2", h=1, cv = TRUE)
hier("htseg2", h=2, cv = TRUE)
hier("htseg2", h=2)
?tsCV
i <- 1
a <- tsCV(ts(allTsTrain[,i]), fets, h=1)
a <- tsCV(eggs, fets, h=1)
length(eggs)
length(a)
a <- tsCV(eggs, fets, h=1, window = 30)
length(a)
b <- tsCV(eggs, fets, h=1)
length(b)
length(a)
b
a
htseg2
length(htseg2)
length(htseg2[[1]])
length(htseg2[[1]][,1])
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier("htseg2", h=2, cv = TRUE)
errs
sigma[i]
abs ( (tmp$mean[h] - tmp$upper[h])  / (qnorm(alpha / 2)) )
h
sigma[i]
sigma[1]
hier("htseg2", h=2)
hier("htseg2", h=1)
hier("htseg2", h=2)
hier("htseg2", h=3)
hier("htseg2", h=1, cv = TRUE)
hier("htseg2", h=2, cv = TRUE)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
?gts
library(gts)
library(hts)
infantgts
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier("infantgts",h=1)
hier("infantgts",h=1, cv = TRUE)
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/hier.R')
hier (infantgts, h=1, fmethod="arima", cv=FALSE)
hier ("infantgts", h=1, fmethod="arima", cv=FALSE)
hier ("infantgts", h=1, fmethod="arima", cv=TRUE)
library(readr)
Sheet_2_Table_1 <- read_csv("tmp.csv/Sheet 2-Table 1.csv",
locale = locale(grouping_mark = "'"))
View(Sheet_2_Table_1)
tmp
tmp <- Sheet_2_Table_1
rank(tmp)
?friedman.test
a <- friedman.test(tmp)
rank(tmp[1,])
tmp[1,]
rank(tmp[1,])
rank(as.numeric(tmp[1,]))
rank(as.numeric(tmp[2,]))
sampleRank <- matrix(ncol=ncol(tmp),nrow=nrow(tmp))
for (i in 1:nrow(tmp)) sampleRank[i,]<-rank(tmp[i,])
for (i in 1:nrow(tmp)) sampleRank[i,]<-rank(as.numeric(tmp[i,]))
tmp
sampleRank
rowMeans(sampleRank)
colMeans(sampleRank)
tmp <- tmp[-1,]
for (i in 1:nrow(tmp)) sampleRank[i,]<-rank(as.numeric(tmp[i,]))
sampleRank
sampleRank <- matrix(ncol=ncol(tmp),nrow=nrow(tmp))
for (i in 1:nrow(tmp)) sampleRank[i,]<-rank(as.numeric(tmp[i,]))
sampleRank
tmp
tmp <- tmp[,-1]
tmp
for (i in 1:nrow(tmp)) sampleRank[i,]<-rank(as.numeric(tmp[i,]))
sampleRank <- matrix(ncol=ncol(tmp),nrow=nrow(tmp))
for (i in 1:nrow(tmp)) sampleRank[i,]<-rank(as.numeric(tmp[i,]))
sampleRank
rowMeans(sampleRank)
colMeans(sampleRank)
