mse <- rbind(matrix(subresults$mseCombMintShr), matrix(subresults$mseBayesShr), matrix(subresults$mseBase))
label <-  factor(rbind(matrix(rep("MinT",resLenght)),matrix(rep("Bayes",resLenght)),
matrix(rep("Base",resLenght))),
levels = c("MinT","Bayes","Base"))
fmethod <- subresults$fmethod
dataPlot <- as.data.frame(mse)
dataPlot$label <- label
currentPlot <- ggplot(dataPlot, aes(x = label, y = mse)) + geom_boxplot()  +
stat_boxplot(geom = "errorbar", width = 0.5) +  #draw the whiskers
scale_x_discrete(name = "") +
scale_y_continuous(name = "Mse") +
ggtitle(paste (dset, "(",fmethod,")"))
scaling <- 1.2 #to avoid large outliers that make the boxplot unreadable
# if (dset=="tourism"){
#   scaling<- 1.1
# }
# else if (fmethod=="ets"){
#   scaling<- 3
# }
ylim1 = boxplot.stats((dataPlot$V1))$stats[c(1, 5)]
currentPlot = currentPlot + coord_cartesian(ylim = ylim1*scaling)  #+ geom_hline(yintercept = 0, color='darkblue', linetype="dashed")
print(currentPlot)
ggsave(pdfname, width = 4, height = 3)
}
#creation of the aggregated results and related graphs
# analysis aggregated over h
for (fmethod in fmethods){
idx = results$fmethod==fmethod
ggBplot(results[idx,])
}
debugSource('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
#creation of the aggregated results and related graphs
# analysis aggregated over h
for (fmethod in fmethods){
idx = results$fmethod==fmethod
ggBplot(results[idx,])
}
dset<-"tourism"
#parse the results of hierarchical non-temporal reconciliation
#readt the mse, extract the proportion of favorable signs and the produces the boxplot
library(readr)
results <- read_csv(paste("results/mse_",dset,".csv",sep=""))
results <- unique(results) #because some experiements on the cluster are duplicated
fmethods <- unique(results$fmethod)
horizons <- unique(results$h)
#we realize that we are only interested in h up to 4
horizons <- horizons[horizons<5]
configs <- length(fmethods) * length(horizons)
#we need first to instantiate the data frame with placeholder values, and then we fill the correct values
comparison <- data.frame(
cases = rep(fmethods[1],configs),
h = rep(1,configs),
fmethod=rep(fmethods[1],configs),
# medianBaseMint=rep(-1,configs),
medianBaseBayesShr=rep(-1,configs),
# medianBaseBayesGlasso=rep(-1,configs),
medianMintBayesShr =rep(-1,configs),
medianBaseMint =rep(-1,configs),
# medianMintBayesGlasso =rep(-1,configs),
# pValMedianMintBayesShr=rep(-1,configs),
# pValMedianMintBayesGlasso=rep(-1,configs),
stringsAsFactors = FALSE
)
aggrComparison <- comparison[1:length(fmethods),]
#analysis for each h
counter <- 1
for (fmethod in fmethods){
for (h in horizons){
print(paste(fmethod,dset))
comparison$fmethod[counter] <- fmethod
idx = results$fmethod==fmethod & results$h==h
if (sum(idx)>0){
subresults <- results[idx,]
comparison$cases[counter] <- sum(idx)
comparison$fmethod[counter] <- fmethod
comparison$h[counter] <- h
# comparison$medianBaseMint[counter] <- median(subresults$mseBase / subresults$mseCombMintShr)
comparison$medianBaseBayesShr[counter] <- round ( median(subresults$mseBase / subresults$mseBayesShr), digits = 2)
# comparison$medianBaseBayesGlasso[counter] <- median(subresults$mseBase / subresults$mseBayesGlasso)
comparison$medianMintBayesShr[counter] <- round ( median(subresults$mseCombMintShr / subresults$mseBayesShr), digits = 2)
comparison$medianBaseMint[counter] <- round ( median(subresults$mseBase / subresults$mseCombMintShr), digits = 2)
# comparison$medianMintBayesGlasso[counter] <- median(subresults$mseCombMintShr / subresults$mseBayesGlasso)
# comparison$pValMedianMintBayesShr[counter] <- wilcox.test(log(subresults$mseCombMintShr/ subresults$mseBayesShr),
# alternative="less")$p.value
# comparison$pValMedianMintBayesGlasso[counter] <- wilcox.test(log(subresults$mseCombMintShr / subresults$mseBayesGlasso),
# alternative="less")$p.value
}
counter <- counter + 1
}
filename=paste("results/summaryEachH_",dset,".csv",sep="")
write.table(comparison,file=filename,sep=",",row.names = FALSE)
#creation of the aggregated results and related graphs
# analysis aggregated over h
for (fmethod in fmethods){
idx = results$fmethod==fmethod
ggBplot(results[idx,])
}
debugSource('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
#creation of the aggregated results and related graphs
# analysis aggregated over h
for (fmethod in fmethods){
idx = results$fmethod==fmethod
ggBplot(results[idx,])
}
debugSource('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
dset <- "infantgts"
#this helping function generates boxplot of the mae
#generate the bplot with ggplot2
ggBplot <- function (subresults){
library(ggplot2)
pdfname <- paste("results/plot","_",dset,"_",fmethod,".pdf",sep = "")
resLenght <- length(subresults$mseBase)
mse <- rbind(matrix(subresults$mseCombMintShr), matrix(subresults$mseBayesShr), matrix(subresults$mseBase))
label <-  factor(rbind(matrix(rep("MinT",resLenght)),matrix(rep("Bayes",resLenght)),
matrix(rep("Base",resLenght))),
levels = c("MinT","Bayes","Base"))
fmethod <- subresults$fmethod
dataPlot <- as.data.frame(mse)
dataPlot$label <- label
currentPlot <- ggplot(dataPlot, aes(x = label, y = mse)) + geom_boxplot()  +
stat_boxplot(geom = "errorbar", width = 0.5) +  #draw the whiskers
scale_x_discrete(name = "") +
scale_y_continuous(name = "Mse") +
ggtitle(paste (dset, paste0("(",fmethod,")")))
scaling <- 1.2 #to avoid large outliers that make the boxplot unreadable
if (dset=="tourism"){
scaling <- 1.1
}
ylim1 = boxplot.stats((dataPlot$V1))$stats[c(1, 5)]
currentPlot = currentPlot + coord_cartesian(ylim = ylim1*scaling)  #+ geom_hline(yintercept = 0, color='darkblue', linetype="dashed")
print(currentPlot)
ggsave(pdfname, width = 4, height = 3)
}
#parse the results of hierarchical non-temporal reconciliation
#readt the mse, extract the proportion of favorable signs and the produces the boxplot
library(readr)
results <- read_csv(paste("results/mse_",dset,".csv",sep=""))
results <- unique(results) #because some experiements on the cluster are duplicated
fmethods <- unique(results$fmethod)
horizons <- unique(results$h)
#we realize that we are only interested in h up to 4
horizons <- horizons[horizons<5]
configs <- length(fmethods) * length(horizons)
#we need first to instantiate the data frame with placeholder values, and then we fill the correct values
comparison <- data.frame(
cases = rep(fmethods[1],configs),
h = rep(1,configs),
fmethod=rep(fmethods[1],configs),
# medianBaseMint=rep(-1,configs),
medianBaseBayesShr=rep(-1,configs),
# medianBaseBayesGlasso=rep(-1,configs),
medianMintBayesShr =rep(-1,configs),
medianBaseMint =rep(-1,configs),
# medianMintBayesGlasso =rep(-1,configs),
# pValMedianMintBayesShr=rep(-1,configs),
# pValMedianMintBayesGlasso=rep(-1,configs),
stringsAsFactors = FALSE
)
aggrComparison <- comparison[1:length(fmethods),]
#analysis for each h
counter <- 1
for (fmethod in fmethods){
for (h in horizons){
print(paste(fmethod,dset))
comparison$fmethod[counter] <- fmethod
idx = results$fmethod==fmethod & results$h==h
if (sum(idx)>0){
subresults <- results[idx,]
comparison$cases[counter] <- sum(idx)
comparison$fmethod[counter] <- fmethod
comparison$h[counter] <- h
# comparison$medianBaseMint[counter] <- median(subresults$mseBase / subresults$mseCombMintShr)
comparison$medianBaseBayesShr[counter] <- round ( median(subresults$mseBase / subresults$mseBayesShr), digits = 2)
# comparison$medianBaseBayesGlasso[counter] <- median(subresults$mseBase / subresults$mseBayesGlasso)
comparison$medianMintBayesShr[counter] <- round ( median(subresults$mseCombMintShr / subresults$mseBayesShr), digits = 2)
comparison$medianBaseMint[counter] <- round ( median(subresults$mseBase / subresults$mseCombMintShr), digits = 2)
# comparison$medianMintBayesGlasso[counter] <- median(subresults$mseCombMintShr / subresults$mseBayesGlasso)
# comparison$pValMedianMintBayesShr[counter] <- wilcox.test(log(subresults$mseCombMintShr/ subresults$mseBayesShr),
# alternative="less")$p.value
# comparison$pValMedianMintBayesGlasso[counter] <- wilcox.test(log(subresults$mseCombMintShr / subresults$mseBayesGlasso),
# alternative="less")$p.value
}
counter <- counter + 1
}
filename=paste("results/summaryEachH_",dset,".csv",sep="")
write.table(comparison,file=filename,sep=",",row.names = FALSE)
#creation of the aggregated results and related graphs
# analysis aggregated over h
for (fmethod in fmethods){
idx = results$fmethod==fmethod & results$h==1
ggBplot(results[idx,])
}
parseHierResults("infantgts")
parseHierResults("tourism")
parseHierResults("infantgts")
dset<-"infantgts"
#parse the results of hierarchical non-temporal reconciliation
#readt the mse, extract the proportion of favorable signs and the produces the boxplot
library(readr)
results <- read_csv(paste("results/mse_",dset,".csv",sep=""))
results <- unique(results) #because some experiements on the cluster are duplicated
fmethods <- unique(results$fmethod)
horizons <- unique(results$h)
#we realize that we are only interested in h up to 4
horizons <- horizons[horizons<5]
configs <- length(fmethods) * length(horizons)
#we need first to instantiate the data frame with placeholder values, and then we fill the correct values
comparison <- data.frame(
cases = rep(fmethods[1],configs),
h = rep(1,configs),
fmethod=rep(fmethods[1],configs),
# medianBaseMint=rep(-1,configs),
medianBaseBayesShr=rep(-1,configs),
# medianBaseBayesGlasso=rep(-1,configs),
medianMintBayesShr =rep(-1,configs),
medianBaseMint =rep(-1,configs),
# medianMintBayesGlasso =rep(-1,configs),
# pValMedianMintBayesShr=rep(-1,configs),
# pValMedianMintBayesGlasso=rep(-1,configs),
stringsAsFactors = FALSE
)
aggrComparison <- comparison[1:length(fmethods),]
#analysis for each h
counter <- 1
for (fmethod in fmethods){
for (h in horizons){
print(paste(fmethod,dset))
comparison$fmethod[counter] <- fmethod
idx = results$fmethod==fmethod & results$h==h
if (sum(idx)>0){
subresults <- results[idx,]
comparison$cases[counter] <- sum(idx)
comparison$fmethod[counter] <- fmethod
comparison$h[counter] <- h
# comparison$medianBaseMint[counter] <- median(subresults$mseBase / subresults$mseCombMintShr)
comparison$medianBaseBayesShr[counter] <- round ( median(subresults$mseBase / subresults$mseBayesShr), digits = 2)
# comparison$medianBaseBayesGlasso[counter] <- median(subresults$mseBase / subresults$mseBayesGlasso)
comparison$medianMintBayesShr[counter] <- round ( median(subresults$mseCombMintShr / subresults$mseBayesShr), digits = 2)
comparison$medianBaseMint[counter] <- round ( median(subresults$mseBase / subresults$mseCombMintShr), digits = 2)
# comparison$medianMintBayesGlasso[counter] <- median(subresults$mseCombMintShr / subresults$mseBayesGlasso)
# comparison$pValMedianMintBayesShr[counter] <- wilcox.test(log(subresults$mseCombMintShr/ subresults$mseBayesShr),
# alternative="less")$p.value
# comparison$pValMedianMintBayesGlasso[counter] <- wilcox.test(log(subresults$mseCombMintShr / subresults$mseBayesGlasso),
# alternative="less")$p.value
}
counter <- counter + 1
}
filename=paste("results/summaryEachH_",dset,".csv",sep="")
write.table(comparison,file=filename,sep=",",row.names = FALSE)
fmethod<-"ets"
idx = results$fmethod==fmethod & results$h==1
idx
sum(idx)
ggBplot(results[idx,])
fmethod<-"arima"
idx = results$fmethod==fmethod & results$h==1
sum(idx)
ggBplot(results[idx,])
parseHierResults("tourism")
source('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
source('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
source('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
dset
debugSource('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
debugSource('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
source('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
setwd("~/")
setwd("~/switchDrive/paperReconc/hierTsCode")
parseHierResults("tourism")
pdfname
dset
debugSource('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
source('~/switchDrive/paperReconc/hierTsCode/parseHierResults.R')
parseHierResults("tourism")
parseHierResults("infantgts")
library(fpp2)
fit <- ets(ausbeer)
autoplot(fit)
forecast(fit, h=10)
autoplot(forecast(fit, h=10))
summary(fit)
fit <- ets(bicoal)
autoplot(forecast(fit, h=10))
autoplot(fitted(fit))
autoplot(bicoal) +  autolayer(fitted(fit))
summary(fit)
fit <- ets(chicken)
summary(fit)
summary(chicken)
fit <- ets(ausbeer)
summary(fit)
autoplot(forecast(fit, h=10))
summary(fit)
library(fpp2)
autoplot(visitors)
frequency(visitors)
autoplot(diff(visitors, lag=12))
autoplot(diff(diff(visitors, lag=12))
)
nsdiffs(visitors)
ndiffs(diff(visitors, lag=12))
fit <- auto.arima(guinearice)
autoplot(forecast(fit, h=20))
ggtsdisplay(internet)
ggtsdisplay(diff(internet))
?internet
ggtsdisplay(diff(diff(internet)))
auto.arima(internet)
fit<-auto.arima(internet)
accuracy(fit)
fit2<-auto.arima(internet, d=2)
accuracy(fit2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=1)
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
library(readr)
# reps <- 2500
reps <- 20
n=120
reps < - 10
reps <- 10
for (i in 1:reps){
hierRec(dset="syntheticLarge", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/",dset,".csv",sep="")
library(readr)
mse_largeSynthetic_n120 <- read_csv("results/mse_largeSynthetic_n120.csv")
View(mse_largeSynthetic_n120)
library(readr)
dataset <- read_csv(NULL)
View(dataset)
library(readr)
mse_largeSynthetic_n120 <- read_csv("results/mse_largeSynthetic_n120.csv")
View(mse_largeSynthetic_n120)
currentData <- mse_largeSynthetic_n120
currentData
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=2)
dataFrame
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec("syntheticLarge", synth_n = 110, seed=1)
hierRec("syntheticLarge", synth_n = 110, seed=2)
hierRec("syntheticLarge", synth_n = 110, seed=3)
hierRec("syntheticLarge", synth_n = 110, seed=4)
source('~/switchDrive/paperReconc/hierTsCode/batchLargeSynth.R')
reps <- 5
n = 25
reps <- 5
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData <- na.omit(currentData)
currentData
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
dataFrame
source('~/switchDrive/paperReconc/hierTsCode/batchLargeSynth.R')
colnames(dataFrame) <- c("fmethod", "sampleSize",  "mintSample/BayesSample",
"MintShr/BayesShr", "BayesShr/Base")
filename <- "results/summaryLargeSynthetic.csv"
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
dataFrame
library(readr)
reps <- 5
n <- 10
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData <- na.omit(currentData)
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
currentData
currentData$h
currentData$fmethod
currentData
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData
n <- 100
for (i in 1:reps){
hierRec(dset="syntheticLarge", fmethod = "arima", seed=i, synth_n = n)
}
#we need to load the same file in which hierRec has written the results
dset <- paste0("largeSynthetic_n",n)
filename <- paste0("results/mse_",dset,".csv",sep="")
currentData <- read_csv(filename)
currentData
currentData <- na.omit(currentData)
currentData
#summarize and save the results
dataFrame <- data.frame(
currentData$fmethod[1],
currentData$sampleSize[1],
median(currentData$mseMintSample/currentData$mseBayesSample),
# median(currentData$mseCombMintShr/currentData$mseBayesGlasso),
# median(currentData$mseBayesDiag/currentData$mseBayesGlasso),
median(currentData$mseMintShr/currentData$mseBayesShr),
median(currentData$mseBayesShr/currentData$mseBase)
)
colnames(dataFrame) <- c("fmethod", "sampleSize",  "mintSample/BayesSample",
"MintShr/BayesShr", "BayesShr/Base")
filename <- "results/summaryLargeSynthetic.csv"
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
write.table(dataFrame, file=filename, append = TRUE, sep=",", row.names = FALSE, col.names = writeNames)
?visitors
library(fpp2)
?visitors
nsdiffs(visitors)
ndiffs( diff(visitors, lag=12))
autoplot(visitors, lag=12)
autoplot(diff(visitors, lag=12))
autoplot(diff(diff(visitors, lag=12)))
library(fpp2)
fit <- auto.arima(internet)
fit
?auto.arima
fit <- auto.arima(internet, start.p = 3)
fit
fit <- auto.arima(internet, stepwise=FALSE)
fit
library(fpp2)
autoplot(visitors)
nsdiffs(visitors)
nsdiffs( log (visitors))
nsdiffs( visitors)
autoplot(diff(visitors, lag=12))
ndiffs(diff(visitors, lag=12))
autoplot(ausbeer)
nsdiffs(ausbeer)
?ausbeer
autoplot( diff (ausbeer, lag=4 ))
ndiffs( diff (ausbeer, lag=4 ))
autoplot diff(( diff (ausbeer, lag=4 )))
autoplot (diff(( diff (ausbeer, lag=4 ))))
autoplot(rice)
autoplot(guinearice)
fit <- auto.arima(guinearice)
fit
autoplot( forecast(fit))
autoplot(internet)
?internet
autoplot(internet)
fit <- auto.arima(internet)
fit
autoplot(diff(internet))
