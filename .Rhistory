allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
#shrink to the diagonal
library(stats)
library(corrplot)
residuals
dim(residuals)
dset<-"tourism"
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R', echo=TRUE)
library(hts)
library(huge)#covariance matrix via glasso
library(SHIP)#shrinkage of covarianca matrix
source("loadTourism.R")
set.seed(seed)
if (dset=="tourism"){
hierTs <- loadTourism()
}
else if (dset=="infantgts"){
hierTs <- infantgts
}
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
h<-1
iTest<-1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#sometimes the sample matrix is not positive definite and minT crashes
#the matrix is computed internally by minT and cannot be controlled from here.
fcastCombMintShr <-
forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod,
covariance="shr")
fmethod<-"ets"
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
residuals
dset
source("loadTourism.R")
set.seed(seed)
hierTs <- loadTourism()
hierTs
testSize <- 50
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
train
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
allTsTrain
train
allTsTrain[[1]]
allTsTrain[1,]
allTsTrain[,1]
allTsTrain[,2]
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i], additive.only = TRUE)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
}
tmp <- forecast(model, h=h, level=1-alpha)
residuals[,i] <- model$residuals #we could store model$residuals if we allowed  multiplicative errors
fitted[,i] <- model$fitted
actual[,i] <- model$x
preds[i] <- tmp$mean[h]
#the reconciliation matrix does always refer to h=1
sigma[i] <- abs ( (tmp$mean[1] - tmp$upper[1])  / (qnorm(alpha / 2)) )
}
#shrink to the diagonal
library(stats)
library(corrplot)
pdf(file = "CovErrorsShr.pdf")
shCov <-  shrink.estim(residuals, tar=build.target(residuals,type="D"))[[1]]
shCor <-  cov2cor(shCov)
colnames(shCor) <- colnames(allTsTrain)
rownames(shCor) <- colnames(allTsTrain)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = paste0(dset,"CovLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperErrorsShr.pdf"))
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
pdf(file = paste0(dset,"CovY.pdf"))
corY <- cor(actual)
colnames(corY) <- colnames(allTsTrain)
rownames(corY) <- colnames(allTsTrain)
corrplot(corY, method = "circle", title = "Y correlations")
dev.off()
shCor[bottomIdx,upperIdx]
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
if (dset=="infantgts"){
colnames(shCor) <- colnames(allTsTrain)
rownames(shCor) <- colnames(allTsTrain)
}
shCov <-  shrink.estim(residuals, tar=build.target(residuals,type="D"))[[1]]
shCor <-  cov2cor(shCov)
corrplot(shCor, method = "circle", title = "residual correlation after shrinkage")
dev.off()
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
pdf(file = paste0(dset,"CovLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,bottomIdx], method = "circle", title = "botton residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperErrorsShr.pdf"))
corrplot(shCor[upperIdx,upperIdx], method = "circle", title = "upper residuals")
dev.off()
pdf(file = paste0(dset,"CovUpperLowerErrorsShr.pdf"))
corrplot(shCor[bottomIdx,upperIdx], method = "circle", title = "upper - lower")
dev.off()
shCor[upperIdx,upperIdx]
summary(shCor[upperIdx,upperIdx])
summary(as.vector(shCor[upperIdx,upperIdx]))
summary(as.vector(shCor[upperIdx,bottomIdx]))
summary(as.vector(shCor[upperIdx,upper.tri()]))
summary(as.vector(shCor[upperIdx,upperIdx])
)
summary(as.vector(shCor[upperIdx,upperIdx]))
summary(as.vector(shCor[bottomIdx,bottomIdx]))
summary(as.vector(shCor[upperIdx,bottomIdx]))
source('~/switchDrive/paperReconc/hierTsCode/covarAnalysis.R')
.libPaths()
shrink.estimMINT <- function(x, tar)
{
if (is.matrix(x) == TRUE && is.numeric(x) == FALSE)
stop("The data matrix must be numeric!", call. = FALSE)
p <- ncol(x)
n <- nrow(x)
covm <- crossprod(x) / n
corm <- cov2cor(covm)
xs <- scale(x, center = FALSE, scale = sqrt(diag(covm)))
v <- (1/(n * (n - 1))) * (crossprod(xs^2) - 1/n * (crossprod(xs))^2)
diag(v) <- 0
corapn <- cov2cor(tar)
d <- (corm - corapn)^2
lambda <- sum(v)/sum(d)
lambda <- max(min(lambda, 1), 0)
shrink.cov <- lambda * tar + (1 - lambda) * covm
return(list(shrink.cov, c("The shrinkage intensity lambda is:",
round(lambda, digits = 4))))
}
shrink.estim()
library(SHIP)
?shrink.estim
x <- matrix(rnorm(20*30),20,30)
shrink.estim(x,tar=build.target(x,type="D"))
a<-shrink.estim(x,tar=build.target(x,type="D"))
b<-shrink.estimMINT(x,tar=build.target(x,type="D"))
b
b[[2]]
a[[2]]
x
b<-shrink.estimMINT(x,tar=build.target(x,type="D"))
a<-shrink.estim(x,tar=build.target(x,type="D"))
a
b
x <- matrix(rnorm(3*30),3,30)
a<-shrink.estim(x,tar=build.target(x,type="D"))
b<-shrink.estimMINT(x,tar=build.target(x,type="D"))
a
b
trace("minT", edit=TRUE)
trace("hts", edit=TRUE)
trace("forecast", edit=TRUE)
library(hts)
trace("forecast", edit=TRUE)
trace("minT", edit=TRUE)
trace(hts::forecast.gts, edit=TRUE)
library(Matrix)
mseBayesShr.minT =  mean  ( (allts(test)[h,] - bayesRecon(covariance="shr-minT"))^2 )
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="syntheticLarge", synth_n = 99)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="syntheticLarge", synth_n = 99)
for (i in (1:100)) hierRec(dset="syntheticLarge", synth_n = 99, seed=i)
library(readr)
mse <- read_csv("results/mse_largeSynthetic_n99.csv")
View(mse)
median(mse$mseMintSample/mse$mseBase)
median(mse$mseCombMintShr/mse$mseBayesGlasso)
median(mse$mseCombMintShr/mse$mseBayesShr)
median(mse$mseCombMintShr/mse$`mseBayesShr-minT`)
for (i in (1:100)) hierRec(dset="syntheticLarge", synth_n = 20, seed=i)
for (i in (1:100)) hierRec(dset="syntheticLarge", synth_n = 25, seed=i)
library(readr)
mse_largeSynthetic_n25 <- read_csv("results/mse_largeSynthetic_n25.csv")
View(mse_largeSynthetic_n25)
library(readr)
mse_largeSynthetic_n25 <- read_csv("results/mse_largeSynthetic_n25.csv"mse_largeSynthetic_n25
summary(mse_largeSynthetic_n25$mseBayesShr / mse_largeSynthetic_n25$`mseBayesShr-minT`)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="syntheticLarge", synth_n = 98, seed=i)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
?shrink.estim
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
for (i in (1:100)) hierRec(dset="syntheticLarge", synth_n = 99, seed=i)
library(readr)
old <- read_csv("results/mse_largeSynthetic_n99OLD.csv")
View(old)
library(readr)
new <- read_csv("results/mse_largeSynthetic_n99.csv")
View(new)
library(readr)
old <- read_csv("results/mse_largeSynthetic_n99OLD.csv")
View(old)
library(readr)
new <- read_csv("results/mse_largeSynthetic_n99.csv")
View(new)
new
head(new$mseBase)
head(old$mseBase)
for (i in (1:2)) hierRec(dset="syntheticLarge", synth_n = 95, seed=i)
head(old)
head(new)
head( old[-,1])
head( old[-1,])
old <-  old[-1,]
head(old)
head(new)
summary(new$mseCombMintShr)
summary(old$mseCombMintShr)
summary(old$mseBayesShr)
summary(new$mseBayesShr)
summary(new$mseCombMintShr / new$mseBayesShr )
summary(new$mseCombMintShr / old$mseBayesShr )
#covariance can be "diagonal", "sam" or "glasso"
bayesRecon <- function (covariance){
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
Y_vec <- preds[upperIdx]
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
bottomResiduals <- residuals[,bottomIdx]
if (covariance=="diagonal"){
priorCov <- diag(bottomVar)
}
else if (covariance=="sam"){
#the covariances are the covariances of the time series
#the variances are the variances of the forecasts, hence the variances of the residuals
priorCov <- cov(bottomResiduals)
}
else if (covariance=="glasso"){
#the covariances are the covariances of the time series
#the variances are the variances of the forecasts, hence the variances of the residuals
out.glasso <- huge(bottomResiduals, method = "glasso", cov.output = TRUE)
out.select <- huge.select(out.glasso, criterion = "ebic")
priorCov <- out.select$opt.cov
}
else if (covariance=="shr"){
sigmaDiag <- diag(bottomVar)
priorCov <-  shrink.estim(bottomResiduals, tar=build.target(bottomResiduals,type="D"))[[1]]
}
upperVar <- sigma[upperIdx]^2
#covariance for the upper time series; we need managing separately the case where only a single time series is present
#as diag will try to create a matrix of size upperVar instead.
upperResiduals <- residuals[,upperIdx]
if (length(upperIdx)==1) {
Sigma_y <- upperVar
}
else if (covariance=="diagonal"){
Sigma_y <- diag(upperVar)
}
#if we only one upper time series, there is no covariance matrix to be estimated.
else if (covariance=="glasso") {
#get variance and covariance of the residuals
out.glasso <- huge(upperResiduals, method = "glasso", cov.output = TRUE)
out.select <- huge.select(out.glasso, criterion = "ebic")
Sigma_y <- out.select$opt.cov
}
else if (covariance=="sam") {
#get variance and covariance of the residuals
Sigma_y <- cov(upperResiduals)
}
else if (covariance=="shr") {
sigma_y_diag <- diag(upperVar)
Sigma_y <-  shrink.estim(upperResiduals, tar=build.target(upperResiduals,type="D"))[[1]]
}
#==updating
#A explains how to combin the bottom series in order to obtain the
# upper series
#if upperIdx contains a single row, R behaves oddily; hence we need to manually manage that case.
if (length(upperIdx)==1){
A <- cbind(S[upperIdx,])
}
else {
A <- t(S[upperIdx,])
}
M <- ncol ( t(A) %*% priorCov %*% A + Sigma_y )
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y + 1e-6*diag(M))
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
return(bayesPreds)
}
#The buReconcile function computes the bu prediction given the predictions (1 x tot time series) and the S matrix
#(tot time series X bottom time series)
#predsAllTs is a flag: is set to true, the input preds contains predictions for all the hierarchy
#and the function retrieves the bottom series; if set to false, this is not needed
#as preds only contains only bottom time series
buReconcile <- function (preds,S, predsAllTs = FALSE) {
bottomPreds <- preds
if (predsAllTs) {
#retrieves the bottom prediction from all predictions
upperIdx <- 1 : (nrow(S) - ncol(S))
bottomIdx <- setdiff (1:nrow(S), upperIdx)
bottomPreds <- preds [,bottomIdx]
}
buPreds <- preds
#nrow(S) is the total number of time series
for (i in 1:nrow(S)){
buPreds[i] <- S[i,] %*% bottomPreds
}
return (buPreds)
}
#check the calibration of the prediction interval with coverage (1-currentAlpha)
checkCalibration <- function(preds,sigmas,htsActual,coverage){
stdQuant <- abs(qnorm((1-coverage)/2))
included <- vector(length = length(preds))
actual <- allts(htsActual)[h,]
for (ii in seq_along(preds)){
upper <- preds[ii] + stdQuant * sigmas[ii]
lower <- preds[ii] - stdQuant * sigmas[ii]
included[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included))
}
hierMse <- function (htsPred, htsActual, h) {
#receives two hts objects, containing  forecast and actual value.
#computes the mse for the whole hierarchy.
mse <- mean  ( (allts(htsPred)[h,] - allts(htsActual)[h,])^2 )
return (mse)
}
if (dset=="tourism"){
hierTs <- loadTourism()
}
hierTs <- loadTourism()
library(hts)
library(huge)#covariance matrix via glasso
library(SHIP)#shrinkage of covarianca matrix
source("loadTourism.R")
hierTs <- loadTourism()
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
h=1
iTest=1
#here the experiment starts
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
i <- 1
model <- ets(allTsTrain[,i], additive.only = TRUE)
library(hts)
model <- ets(allTsTrain[,i], additive.only = TRUE)
a
model <- ets(allTsTrain[,i], additive.only = TRUE)
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
model <- ets(allTsTrain[,i], additive.only = TRUE)
model
i <- 150
model <- ets(allTsTrain[,i], additive.only = TRUE)
model
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="tourism", shortTrain = TRUE)
hierRec(dset="infantgts", shortTrain = TRUE)
length(allTsTrain[,i])
?sample
sample.int(20)
sample.int(20, size=1)
length(allTsTrain[,i])
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="tourism", shortTrain = TRUE, iTest = 1)
startTrain
endTrain
#recompute predictions to be  accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#the residuals for the model fitted on each time series
residuals <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
fitted <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
actual <- matrix(nrow=dim(allTsTrain)[1], ncol = numTs)
i <- 1
model <- ets(allTsTrain[,i], additive.only = TRUE)
(allTsTrain[,i])
hierRec(dset="tourism", shortTrain = TRUE, iTest = 1)
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="tourism",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
hierRec(dset="infantgts",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
hierRec(hierRec())
hierRec
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="infantgts",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
hierRec(dset="tourism",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
timeIdx
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="tourism",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
source('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec(dset="tourism",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R')
hierRec(dset="tourism",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
hierRec(dset="infantgts",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
debugSource('~/switchDrive/paperReconc/hierTsCode/hierRec.R', echo=TRUE)
hierRec(dset="infantgts",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
hierRec(dset="tourism",h=1,fmethod="ets",iTest=1,shortTrain=TRUE)
