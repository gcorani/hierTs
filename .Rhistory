parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH <- function (dset){
#parse the results of hierarchical non-temporal reconciliation
#readt the mse, extract the proportion of favorable signs and the produces the boxplot
library(readr)
results <- read_csv(paste("results/mseHierReconc",dset,".csv",sep=""))
results <- unique(results) #because some experiements on the cluster are duplicated
fmethods <- unique(results$fmethod)
dsets <- unique(results$dset)
configs <- length(fmethods) * length(dsets)
#the 7 fields are fmethod, dset, prop against each method
# header <- c("dset","fmethod","h","propBeatBase","propBeatBu","propBeatComb",
# "propBeatCombWls","propBeatMint")
# favorableProps <- matrix(nrow = configs, ncol = length(header))
#we need first to instantiate the data frame with placeholder values, and then we fill the correct values
favorableProps <- data.frame(dset=rep(dsets[1],configs),
fmethod=rep(fmethods[1],configs),
propBeatBase=rep(-1,configs),
propBeatMint=rep(-1,configs),
medianBaseBayes=rep(-1,configs),
medianMintBayes=rep(-1,configs),
propCorrBeatBase=rep(-1,configs),
propCorrBeatMint=rep(-1,configs),
medianBaseBayesCorr=rep(-1,configs),
medianMintBayesCorr=rep(-1,configs),
stringsAsFactors = FALSE
)
counter <- 1
for (dset in dsets){
for (fmethod in fmethods){
print(paste(fmethod,dset))
favorableProps$dset[counter] <- dset
favorableProps$fmethod[counter] <- fmethod
idx = results$fmethod==fmethod & results$dset==dset
if (sum(idx)>0){
subresults <- results[idx,]
favorableProps$propBeatBase[counter] <- mean (subresults$mseBase>subresults$mseBayes)
favorableProps$propBeatMint[counter] <- mean (subresults$mseCombMint>subresults$mseBayes)
favorableProps$medianBaseBayes[counter] <- median(subresults$mseBase / subresults$mseBayes)
favorableProps$medianMintBayes[counter] <- median(subresults$mseCombMint / subresults$mseBayes)
favorableProps$propCorrBeatBase[counter] <- mean (subresults$mseBase>subresults$mseBayesCorr)
favorableProps$propCorrBeatMint[counter] <- mean (subresults$mseCombMint>subresults$mseBayesCorr)
favorableProps$medianBaseBayesCorr[counter]  <- median(subresults$mseBase / subresults$mseBayesCorr)
favorableProps$medianMintBayesCorr[counter] <- median(subresults$mseCombMint / subresults$mseBayesCorr)
#generate the bplot with ggplot2
library(ggplot2)
pdfname <- paste("results/plot","_",dset,"_",fmethod,".pdf",sep = "")
denom <- subresults$mseBase
resLenght <- length(subresults$mseBase)
#old code, 3 models
# relMse <- rbind(matrix(subresults$mseCombMint/denom), matrix(subresults$mseBayes/denom), matrix(subresults$mseBayesCorr/denom))
# label <-  factor(rbind(matrix(rep("Mint",resLenght)),matrix(rep("Bayes",resLenght)),matrix(rep("Bayes (corr)",resLenght))),
# levels = c("Mint","Bayes","Bayes (corr)"))
#new code, 2 models (minT and Bayes corr)
relMse <- rbind(matrix(subresults$mseCombMint/denom), matrix(subresults$mseBayesCorr/denom))
label <-  factor(rbind(matrix(rep("Mint",resLenght)),matrix(rep("Bayes (corr)",resLenght))),
levels = c("Mint","Bayes (corr)"))
dataPlot <- as.data.frame(relMse)
dataPlot$label <- label
currentPlot <- ggplot(dataPlot, aes(x = label, y = log10(relMse))) + geom_boxplot()  +
stat_boxplot(geom = "errorbar", width = 0.5) +  #draw the whiskers
scale_x_discrete(name = "") +
scale_y_continuous(name = "Log10 (mse / mse(base)) ")
ylim1 = boxplot.stats(log(dataPlot$V1))$stats[c(1, 5)]
currentPlot = currentPlot + coord_cartesian(ylim = ylim1*1.3)  + geom_hline(yintercept = 0, color='darkblue')
print(currentPlot)
ggsave(pdfname, width = 4, height = 3)
counter <- counter + 1
}
filename=paste("results/summary",dset,".csv",sep="")
write.table(favorableProps,file=filename,sep=",",row.names = FALSE)
return (favorableProps)
}
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
parseHierResults_aggregatedH("tourism")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("tourism")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("tourism")
parseHierResults_aggregatedH("infantgt")
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
parseHierResults_aggregatedH("tourism")
10^0.2
?Error
error
error("pippo")
#prepares the AEdemand dataset and launches the temporal reconciliation experiment
#the fmethod is forced to be arima as the expsmoothing does not support such long seasonality
library(thief)
library(fpp2)
source("temporalRec.R")
#finestra di 40 esperimenti su 13-weeks ahead forecast
totExp=20
i<-1
currentExp<-1
print(paste("AEdemand: ",colnames(AEdemand)[i]))
freq <- frequency(AEdemand[,i])
n <- length(AEdemand[,i])
endTrain <- time(AEdemand[,i])[n - freq - currentExp ]
startTest <- time(AEdemand[,i])[n - freq - currentExp + 1]
train <- window(AEdemand[,i], end=endTrain)
test <- window(AEdemand[,i], start=startTest)
tsObj<- list()
tsObj$x <- train
tsObj$xx <- test
tsObj$sn <- colnames(AEdemand)[i]
temporalRec (tsObj, fmethod=fmethod, periodType="weekly")
temporalRec (tsObj, fmethod="ets", periodType="weekly")
sigma
variances<-sigma^@
variances<-sigma^2
variances
sum(variances[1:12])
numTs
frequency(trainHier[[1]])
sum(variances[1:52])
frequency(trainHier[[2]])
sum(variances[53:53+25])
#prepares the AEdemand dataset and launches the temporal reconciliation experiment
#the fmethod is forced to be arima as the expsmoothing does not support such long seasonality
library(thief)
library(fpp2)
source("temporalRec.R")
#finestra di 40 esperimenti su 13-weeks ahead forecast
totExp=20
i <- 1
currentExp<-1
print(paste("AEdemand: ",colnames(AEdemand)[i]))
freq <- frequency(AEdemand[,i])
n <- length(AEdemand[,i])
endTrain <- time(AEdemand[,i])[n - freq - currentExp ]
startTest <- time(AEdemand[,i])[n - freq - currentExp + 1]
train <- window(AEdemand[,i], end=endTrain)
test <- window(AEdemand[,i], start=startTest)
train
endTrain <- time(AEdemand[,i])[n - freq - currentExp ]
startTest <- time(AEdemand[,i])[n - freq - currentExp + 1]
train <- window(AEdemand[,i], end=endTrain)
test <- window(AEdemand[,i], start=startTest)
tsObj<- list()
tsObj$x <- train
tsObj$xx <- test
tsObj$sn <- colnames(AEdemand)[i]
fmethod<-"ets"
periodType="weekly"
tsObj
tsObj1<-tsObj
library(fpp2)
library(hts)
library(thief)
# computes mae for temporal hierarchies
#both actual and forecast are temporal hierarchies
#it  averages the  different time series having the same frequency
getHierMae <- function (actual, forecast) {
hierMae <- vector(length = length(forecast))
for (i in seq_along(forecast)) {
hierMae[i] <- mean( abs (forecast[[i]]$mean - actual[[i]]) )
}
return (hierMae)
}
globalMse <- function (actual, forecast) {
mse <- 0
for (i in seq_along(forecast)) {
mse <- mse + sum ( (forecast[[i]]$mean - actual[[i]])^2 )
}
return (mse)
}
calibration <- function (actual, forecast, sigmas) {
included50 <- as.vector(rep(0,length(actual)))
included80 <- as.vector(rep(0,length(actual)))
#implementation to be finalized
for (ii in seq_along(forecast)) {
upper50 <- as.numeric(fc[[i]]$upper[,"50%"])
lower50 <- as.numeric(fc[[i]]$lower[,"50%"])
included50[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
upper80 <- as.numeric(fc[[i]]$upper[,"80%"])
lower80 <- as.numeric(fc[[i]]$lower[,"80%"])
included80[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included50),mean(included80))
}
#builds the A matrix, which indicates  which bottom time series sum up to each upper time series.
buildMatrix <- function() {
A <- matrix(data = 0, nrow = length(upperIdx), ncol = length(bottomIdx))
maxFreq <- frequency(trainHier[[1]])
counter <- 1
for (ii in (2:length(trainHier))){
currentFreq <- frequency(trainHier[[ii]])
aggregatedTs <- currentFreq
howManyBottomToSum <- maxFreq / currentFreq
offset <- 1
for (jj in (1:aggregatedTs)) {
A[counter, offset : (offset + howManyBottomToSum - 1)] <- 1
offset <- offset + howManyBottomToSum
counter <- counter + 1
}
return (t(A))
}
#coverage of the PI is 0.8
alpha <- 0.2
#default test set for the M3 is 18 months for the monthly (tp be adapted) and 8 quarters for the quarterly.
#for the moment force the test to be as long as exactly one period
#we should implement a mechanism for doing repeated predictions
train <- tsObj$x
trainHier <- tsaggregates(train)
timeIdx <- time(tsObj$xx)
trainHier
currentExp <- 2
freq <- frequency(AEdemand[,i])
n <- length(AEdemand[,i])
endTrain <- time(AEdemand[,i])[n - freq - currentExp ]
startTest <- time(AEdemand[,i])[n - freq - currentExp + 1]
train <- window(AEdemand[,i], end=endTrain)
test <- window(AEdemand[,i], start=startTest)
tsObj<- list()
tsObj$x <- train
tsObj$xx <- test
tsObj$sn <- colnames(AEdemand)[i]
tsObj2<-tsObj2
tsObj2<-tsObj
train2<-tsObj2$xx
train2<-tsObj2$x
trainHier2 <- tsaggregates(train2)
trainHier2
trainHier2["4-Weekly"]
trainHier1["4-Weekly"]
trainHier["4-Weekly"]
trainHier["Weekly"]
trainHier2["Weekly"]
trainHier2["2-Weekly"]
parseHierResults_aggregatedH <- function (dset){
#parse the results of hierarchical non-temporal reconciliation
#readt the mse, extract the proportion of favorable signs and the produces the boxplot
library(readr)
results <- read_csv(paste("results/mseHierReconc",dset,".csv",sep=""))
results <- unique(results) #because some experiements on the cluster are duplicated
fmethods <- unique(results$fmethod)
dsets <- unique(results$dset)
configs <- length(fmethods) * length(dsets)
#the 7 fields are fmethod, dset, prop against each method
# header <- c("dset","fmethod","h","propBeatBase","propBeatBu","propBeatComb",
# "propBeatCombWls","propBeatMint")
# favorableProps <- matrix(nrow = configs, ncol = length(header))
#we need first to instantiate the data frame with placeholder values, and then we fill the correct values
favorableProps <- data.frame(dset=rep(dsets[1],configs),
fmethod=rep(fmethods[1],configs),
propBeatBase=rep(-1,configs),
propBeatMint=rep(-1,configs),
medianBaseBayes=rep(-1,configs),
medianMintBayes=rep(-1,configs),
propCorrBeatBase=rep(-1,configs),
propCorrBeatMint=rep(-1,configs),
medianBaseBayesCorr=rep(-1,configs),
medianMintBayesCorr=rep(-1,configs),
stringsAsFactors = FALSE
)
counter <- 1
for (dset in dsets){
for (fmethod in fmethods){
print(paste(fmethod,dset))
favorableProps$dset[counter] <- dset
favorableProps$fmethod[counter] <- fmethod
idx = results$fmethod==fmethod & results$dset==dset
if (sum(idx)>0){
subresults <- results[idx,]
favorableProps$propBeatBase[counter] <- mean (subresults$mseBase>subresults$mseBayes)
favorableProps$propBeatMint[counter] <- mean (subresults$mseCombMint>subresults$mseBayes)
favorableProps$medianBaseBayes[counter] <- median(subresults$mseBase / subresults$mseBayes)
favorableProps$medianMintBayes[counter] <- median(subresults$mseCombMint / subresults$mseBayes)
favorableProps$propCorrBeatBase[counter] <- mean (subresults$mseBase>subresults$mseBayesCorr)
favorableProps$propCorrBeatMint[counter] <- mean (subresults$mseCombMint>subresults$mseBayesCorr)
favorableProps$medianBaseBayesCorr[counter]  <- median(subresults$mseBase / subresults$mseBayesCorr)
favorableProps$medianMintBayesCorr[counter] <- median(subresults$mseCombMint / subresults$mseBayesCorr)
#generate the bplot with ggplot2
library(ggplot2)
pdfname <- paste("results/plot","_",dset,"_",fmethod,".pdf",sep = "")
denom <- subresults$mseBase
resLenght <- length(subresults$mseBase)
#old code, 3 models
# relMse <- rbind(matrix(subresults$mseCombMint/denom), matrix(subresults$mseBayes/denom), matrix(subresults$mseBayesCorr/denom))
# label <-  factor(rbind(matrix(rep("Mint",resLenght)),matrix(rep("Bayes",resLenght)),matrix(rep("Bayes (corr)",resLenght))),
# levels = c("Mint","Bayes","Bayes (corr)"))
#new code, 2 models (minT and Bayes corr)
relMse <- rbind(matrix(subresults$mseCombMint/denom), matrix(subresults$mseBayesCorr/denom))
label <-  factor(rbind(matrix(rep("Mint",resLenght)),matrix(rep("Bayes (corr)",resLenght))),
levels = c("Mint","Bayes (corr)"))
dataPlot <- as.data.frame(relMse)
dataPlot$label <- label
currentPlot <- ggplot(dataPlot, aes(x = label, y = log10(relMse))) + geom_boxplot()  +
stat_boxplot(geom = "errorbar", width = 0.5) +  #draw the whiskers
scale_x_discrete(name = "") +
scale_y_continuous(name = "Log10 ( mse / mse(base) ) ")
scaling <- 1.8 #to avoid large outliers that make the boxplot unreadable
if (dset=="tourism"){
scaling<- 1.1
}
else if (fmethod=="ets"){
scaling<- 3
}
ylim1 = boxplot.stats(log(dataPlot$V1))$stats[c(1, 5)]
currentPlot = currentPlot + coord_cartesian(ylim = ylim1*scaling)  + geom_hline(yintercept = 0, color='darkblue')
print(currentPlot)
ggsave(pdfname, width = 4, height = 3)
counter <- counter + 1
}
filename=paste("results/summary",dset,".csv",sep="")
write.table(favorableProps,file=filename,sep=",",row.names = FALSE)
return (favorableProps)
}
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/parseHierResults_aggregatedH.R')
parseHierResults_aggregatedH("infantgts")
parseHierResults_aggregatedH("tourism")
print(paste("AEdemand: ",colnames(AEdemand)[i]))
freq <- frequency(AEdemand[,i])
n <- length(AEdemand[,i])
endTrain <- time(AEdemand[,i])[n - freq - currentExp ]
startTest <- time(AEdemand[,i])[n - freq - currentExp + 1]
train <- window(AEdemand[,i], end=endTrain)
test <- window(AEdemand[,i], start=startTest)
tsObj<- list()
tsObj$x <- train
tsObj$xx <- test
i
i<-1
currentExp<-
currentExp<-1
#prepares the AEdemand dataset and launches the temporal reconciliation experiment
#the fmethod is forced to be arima as the expsmoothing does not support such long seasonality
library(thief)
library(fpp2)
source("temporalRec.R")
#finestra di 40 esperimenti su 13-weeks ahead forecast
totExp=20
print(paste("AEdemand: ",colnames(AEdemand)[i]))
freq <- frequency(AEdemand[,i])
n <- length(AEdemand[,i])
endTrain <- time(AEdemand[,i])[n - freq - currentExp ]
startTest <- time(AEdemand[,i])[n - freq - currentExp + 1]
train <- window(AEdemand[,i], end=endTrain)
test <- window(AEdemand[,i], start=startTest)
tsObj<- list()
tsObj$x <- train
tsObj$xx <- test
tsObj$sn <- colnames(AEdemand)[i]
library(fpp2)
library(hts)
library(thief)
# computes mae for temporal hierarchies
#both actual and forecast are temporal hierarchies
#it  averages the  different time series having the same frequency
getHierMae <- function (actual, forecast) {
hierMae <- vector(length = length(forecast))
for (i in seq_along(forecast)) {
hierMae[i] <- mean( abs (forecast[[i]]$mean - actual[[i]]) )
}
return (hierMae)
}
globalMse <- function (actual, forecast) {
mse <- 0
for (i in seq_along(forecast)) {
mse <- mse + sum ( (forecast[[i]]$mean - actual[[i]])^2 )
}
return (mse)
}
calibration <- function (actual, forecast, sigmas) {
included50 <- as.vector(rep(0,length(actual)))
included80 <- as.vector(rep(0,length(actual)))
#implementation to be finalized
for (ii in seq_along(forecast)) {
upper50 <- as.numeric(fc[[i]]$upper[,"50%"])
lower50 <- as.numeric(fc[[i]]$lower[,"50%"])
included50[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
upper80 <- as.numeric(fc[[i]]$upper[,"80%"])
lower80 <- as.numeric(fc[[i]]$lower[,"80%"])
included80[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included50),mean(included80))
}
#builds the A matrix, which indicates  which bottom time series sum up to each upper time series.
buildMatrix <- function() {
A <- matrix(data = 0, nrow = length(upperIdx), ncol = length(bottomIdx))
maxFreq <- frequency(trainHier[[1]])
counter <- 1
for (ii in (2:length(trainHier))){
currentFreq <- frequency(trainHier[[ii]])
aggregatedTs <- currentFreq
howManyBottomToSum <- maxFreq / currentFreq
offset <- 1
for (jj in (1:aggregatedTs)) {
A[counter, offset : (offset + howManyBottomToSum - 1)] <- 1
offset <- offset + howManyBottomToSum
counter <- counter + 1
}
return (t(A))
}
#coverage of the PI is 0.8
alpha <- 0.2
#default test set for the M3 is 18 months for the monthly (tp be adapted) and 8 quarters for the quarterly.
#for the moment force the test to be as long as exactly one period
#we should implement a mechanism for doing repeated predictions
train <- tsObj$x
trainHier <- tsaggregates(train)
trainHier
library(hts)
library(huge)
source("loadTourism.R")
if (is.character(dset) == FALSE) {
stop ("dset should be a string")
}
bayesRecon <- function (correlation){
S <- smatrix(train)
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
Y_vec <- preds[upperIdx]
Sigma_y <- matrix(nrow = length(upperIdx), ncol = length(upperIdx))
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
priorCov <- diag(bottomVar)
if (correlation){
#the covariances are the covariances of the time series
#the variances are the variances of the forecasts, hence the variances of the residuals
bottomResiduals <- residuals[,bottomIdx]
priorCov <- cov(bottomResiduals)
out.glasso <- huge(bottomResiduals, method = "glasso", cov.output = TRUE)
out.select <- huge.select(out.glasso, criterion = "stars")
priorCov <- out.select$opt.cov
}
#covariance for the upper time series
upperVar <- sigma[upperIdx]^2
Sigma_y <- diag(upperVar)
if (correlation){
#get variance and covariance of the residuals
upperResiduals <- residuals[,upperIdx]
Sigma_y <- cov(upperResiduals)
out.glasso <- huge(upperResiduals, method = "glasso", cov.output = TRUE)
out.select <- huge.select(out.glasso, criterion = "stars")
Sigma_y <- out.select$opt.cov
}
#==updating
#A explains how to combin the bottom series in order to obtain the
# upper series
A <- t(S[upperIdx,])
M <- ncol ( t(A) %*% priorCov %*% A + Sigma_y )
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y + 1e-6*diag(M))
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
return(bayesPreds)
}
#The buReconcile function computes the bu prediction given the predictions (1 x tot time series) and the S matrix
#(tot time series X bottom time series)
#predsAllTs is a flag: is set to true, the input preds contains predictions for all the hierarchy
#and the function retrieves the bottom series; if set to false, this is not needed
#as preds only contains only bottom time series
buReconcile <- function (preds,S, predsAllTs = FALSE) {
bottomPreds <- preds
if (predsAllTs) {
#retrieves the bottom prediction from all predictions
upperIdx <- 1 : (nrow(S) - ncol(S))
bottomIdx <- setdiff (1:nrow(S), upperIdx)
bottomPreds <- preds [,bottomIdx]
}
buPreds <- preds
#nrow(S) is the total number of time series
for (i in 1:nrow(S)){
buPreds[i] <- S[i,] %*% bottomPreds
}
return (buPreds)
}
#check the calibration of the prediction interval with coverage (1-currentAlpha)
checkCalibration <- function(preds,sigmas,htsActual,coverage){
stdQuant <- abs(qnorm((1-coverage)/2))
included <- vector(length = length(preds))
actual <- allts(htsActual)[h,]
for (ii in seq_along(preds)){
upper <- preds[ii] + stdQuant * sigmas[ii]
lower <- preds[ii] - stdQuant * sigmas[ii]
included[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included))
}
hierMse <- function (htsPred, htsActual, h) {
#receives two hts objects, containing  forecast and actual value.
#computes the mse for the whole hierarchy.
mse <- mean  ( (allts(htsPred)[h,] - allts(htsActual)[h,])^2 )
return (mse)
}
#extract the time from the data set to then split into train / test (test set contains 25 or 5 time points)
set.seed(seed = 0)
hierTs <- loadTourism()
summary(hierT)
summary(hierTs)
library("thief")
?AEdemand
