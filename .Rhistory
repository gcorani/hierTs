for (i in 1:nrow(S)){
buPreds[i] <- S[i,] %*% bottomPreds
}
return (buPreds)
}
#check the calibration of the prediction interval with coverage (1-currentAlpha)
checkCalibration <- function(preds,sigmas,htsActual,coverage){
stdQuant <- abs(qnorm((1-coverage)/2))
included <- vector(length = length(preds))
actual <- allts(htsActual)[h,]
for (ii in seq_along(preds)){
upper <- preds[ii] + stdQuant * sigmas[ii]
lower <- preds[ii] - stdQuant * sigmas[ii]
included[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included))
}
hierMse <- function (htsPred, htsActual, h) {
#receives two hts objects, containing  forecast and actual value.
#computes the mse for the whole hierarchy.
mse <- mean  ( (allts(htsPred)[h,] - allts(htsActual)[h,])^2 )
return (mse)
}
#extract the time from the data set to then split into train / test (test set contains 25 or 5 time points)
set.seed(seed = 0)
if (dset=="tourism"){
hierTs <- loadTourism()
}
else if (dset=="infantgts"){
hierTs <- infantgts
}
testSize <- 3
for (iTest in 1:possiblePreds) {
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMint       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod)
# mseBu        <- hierMse(fcastBu, test, h )
# mseComb      <- hierMse(fcastComb, test, h )
# mseCombWls   <- hierMse(fcastCombWls, test, h )
mseCombMint  <- hierMse(fcastCombMint, test,  h)
#recompute predictions to be easily accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
# print(paste(as.character(i),"/",as.character(numTs)))
# print(model$components)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
}
preds[i] <- tmp$mean[h]
sigma[i] <- abs ( (tmp$mean[h] - tmp$upper[h])  / (qnorm(alpha / 2)) )
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
calibration50 <- checkCalibration(preds, sigma, test, coverage = 0.5)
calibration80 <- checkCalibration(preds, sigma, test, coverage = 0.8)
S <- smatrix(train)
#Bayesian reconciliation
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
#prior mean and covariance of the upper time series
Y_vec <- preds[upperIdx]
Sigma_y <- matrix(nrow = length(upperIdx), ncol = length(upperIdx))
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
priorCov <- diag(bottomVar)
#covariance for the upper time series
upperVar <- sigma[upperIdx]^2
Sigma_y <- diag(upperVar)
#==updating
#A explains how to combin the bottom series in order to obtain the
# upper series
A <- t(S[upperIdx,])
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y)
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
mseBayes =  mean  ( (allts(test)[h,] - bayesPreds)^2 )
#save to file the results, at every iteration
dataFrame <- data.frame(h, fmethod, dset, calibration50, calibration80, mseBase,mseCombMint,mseBayes)
filename <- paste("results/mseHierReconc",dset,".csv",sep="")
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
write.table(dataFrame, file=filename, append = TRUE, sep=",", row.names = FALSE, col.names = writeNames)
}
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
h=1
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
for (iTest in 1:possiblePreds) {
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMint       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod)
# mseBu        <- hierMse(fcastBu, test, h )
# mseComb      <- hierMse(fcastComb, test, h )
# mseCombWls   <- hierMse(fcastCombWls, test, h )
mseCombMint  <- hierMse(fcastCombMint, test,  h)
#recompute predictions to be easily accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
# print(paste(as.character(i),"/",as.character(numTs)))
# print(model$components)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
}
preds[i] <- tmp$mean[h]
sigma[i] <- abs ( (tmp$mean[h] - tmp$upper[h])  / (qnorm(alpha / 2)) )
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
calibration50 <- checkCalibration(preds, sigma, test, coverage = 0.5)
calibration80 <- checkCalibration(preds, sigma, test, coverage = 0.8)
S <- smatrix(train)
#Bayesian reconciliation
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
#prior mean and covariance of the upper time series
Y_vec <- preds[upperIdx]
Sigma_y <- matrix(nrow = length(upperIdx), ncol = length(upperIdx))
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
priorCov <- diag(bottomVar)
#covariance for the upper time series
upperVar <- sigma[upperIdx]^2
Sigma_y <- diag(upperVar)
#==updating
#A explains how to combin the bottom series in order to obtain the
# upper series
A <- t(S[upperIdx,])
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y)
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
mseBayes =  mean  ( (allts(test)[h,] - bayesPreds)^2 )
#save to file the results, at every iteration
dataFrame <- data.frame(h, fmethod, dset, calibration50, calibration80, mseBase,mseCombMint,mseBayes)
filename <- paste("results/mseHierReconc",dset,".csv",sep="")
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
write.table(dataFrame, file=filename, append = TRUE, sep=",", row.names = FALSE, col.names = writeNames)
}
dset
dset <- "htseg1"
for (iTest in 1:possiblePreds) {
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMint       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod)
# mseBu        <- hierMse(fcastBu, test, h )
# mseComb      <- hierMse(fcastComb, test, h )
# mseCombWls   <- hierMse(fcastCombWls, test, h )
mseCombMint  <- hierMse(fcastCombMint, test,  h)
#recompute predictions to be easily accessed by the Bayesian method
allTsTrain <- allts(train)
numTs <- ncol(allTsTrain)
alpha <- 0.2
sigma <- vector(length = numTs)
preds <- vector(length = numTs)
#compute, for each  ts, predictions and sigma (h-steps ahead)
for (i in 1:numTs){
if (fmethod=="ets"){
model <- ets(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
# print(paste(as.character(i),"/",as.character(numTs)))
# print(model$components)
}
else if (fmethod=="arima"){
model <- auto.arima(allTsTrain[,i])
tmp <- forecast(model, h=h, level=1-alpha)
}
preds[i] <- tmp$mean[h]
sigma[i] <- abs ( (tmp$mean[h] - tmp$upper[h])  / (qnorm(alpha / 2)) )
}
mseBase =  mean  ( (allts(test)[h,] - preds)^2 )
calibration50 <- checkCalibration(preds, sigma, test, coverage = 0.5)
calibration80 <- checkCalibration(preds, sigma, test, coverage = 0.8)
S <- smatrix(train)
#Bayesian reconciliation
bottomIdx <- seq( nrow(S) - ncol(S) +1, nrow(S))
upperIdx <- setdiff(1:nrow(S),bottomIdx)
#prior mean and covariance of the bottom time series
priorMean <- preds[bottomIdx]
#prior mean and covariance of the upper time series
Y_vec <- preds[upperIdx]
Sigma_y <- matrix(nrow = length(upperIdx), ncol = length(upperIdx))
#prior covariance for the bottom time series
bottomVar <- sigma[bottomIdx]^2
priorCov <- diag(bottomVar)
#covariance for the upper time series
upperVar <- sigma[upperIdx]^2
Sigma_y <- diag(upperVar)
#==updating
#A explains how to combin the bottom series in order to obtain the
# upper series
A <- t(S[upperIdx,])
correl <- priorCov %*% A %*%
solve (t(A) %*% priorCov %*% A + Sigma_y)
postMean <- priorMean + correl  %*%
(Y_vec - t(A) %*% priorMean)
bayesPreds <- buReconcile(postMean, S, predsAllTs = FALSE)
mseBayes =  mean  ( (allts(test)[h,] - bayesPreds)^2 )
#save to file the results, at every iteration
dataFrame <- data.frame(h, fmethod, dset, calibration50, calibration80, mseBase,mseCombMint,mseBayes)
filename <- paste("results/mseHierReconc",dset,".csv",sep="")
writeNames <- TRUE
if(file.exists(filename)){
writeNames <- FALSE
}
write.table(dataFrame, file=filename, append = TRUE, sep=",", row.names = FALSE, col.names = writeNames)
}
iTest <- 1
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMint       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod)
?forecast.hts
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMintSam       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod, covariance = "sam")
htseg1
train
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
train
htseg1
hierTs<-htseg1
testSize <- 4
#if h=1, the possible preds are the whole test size lenght;
#if h=2, the possible preds are the (test size lenght -1); etc.
possiblePreds <- testSize - h + 1
iTest <- 1
timeIdx             <- time(hierTs$bts[,1])
endTrain            <- length(timeIdx) - h - (iTest - 1)
train               <- window(hierTs, start = timeIdx[1], end = timeIdx[endTrain] )
test                <- window(hierTs, start =timeIdx[endTrain +1], end=timeIdx[endTrain + h])
train
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMint       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod)
#we focus on mint only
# fcastBu             <- forecast(train, h = h, method = "bu", fmethod = fmethod)
# fcastComb           <- forecast(train, h = h, method = "comb", weights="ols", fmethod=fmethod)
# fcastCombWls        <- forecast(train, h = h, method = "comb", weights="wls", fmethod=fmethod)
fcastCombMintSam       <- forecast(train, h = h, method = "comb", weights="mint", fmethod=fmethod, covariance = "sam")
?infantgts
infantgts
infantgts$bts
dim(infantgts$bts)
infantgts
cor(infantgts$bts)
library(hts)
source("loadTourism.R")
if (is.character(dset) == FALSE) {
stop ("dset should be a string")
}
#The buReconcile function computes the bu prediction given the predictions (1 x tot time series) and the S matrix
#(tot time series X bottom time series)
#predsAllTs is a flag: is set to true, the input preds contains predictions for all the hierarchy
#and the function retrieves the bottom series; if set to false, this is not needed
#as preds only contains only bottom time series
buReconcile <- function (preds,S, predsAllTs = FALSE) {
bottomPreds <- preds
if (predsAllTs) {
#retrieves the bottom prediction from all predictions
upperIdx <- 1 : (nrow(S) - ncol(S))
bottomIdx <- setdiff (1:nrow(S), upperIdx)
bottomPreds <- preds [,bottomIdx]
}
buPreds <- preds
#nrow(S) is the total number of time series
for (i in 1:nrow(S)){
buPreds[i] <- S[i,] %*% bottomPreds
}
return (buPreds)
}
#check the calibration of the prediction interval with coverage (1-currentAlpha)
checkCalibration <- function(preds,sigmas,htsActual,coverage){
stdQuant <- abs(qnorm((1-coverage)/2))
included <- vector(length = length(preds))
actual <- allts(htsActual)[h,]
for (ii in seq_along(preds)){
upper <- preds[ii] + stdQuant * sigmas[ii]
lower <- preds[ii] - stdQuant * sigmas[ii]
included[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included))
}
hierMse <- function (htsPred, htsActual, h) {
#receives two hts objects, containing  forecast and actual value.
#computes the mse for the whole hierarchy.
mse <- mean  ( (allts(htsPred)[h,] - allts(htsActual)[h,])^2 )
return (mse)
}
#extract the time from the data set to then split into train / test (test set contains 25 or 5 time points)
set.seed(seed = 0)
dset="tourism"
hierTs <- loadTourism()
cor(hierTs$bts)
a<-cor(hierTs$bts)
image(a)
mean(a>0.9)
mean(a>0.8)
mean(a>0.7)
mean(abs(a)>0.9)
mean(abs(a)>0.8)
mean(abs(a)>0.7)
mean(abs(a)>0.6)
mean(abs(a)>0.5)
mean(abs(a)>0.4)
mean(abs(a)>0.3)
mean(abs(a)>0.2)
mean(abs(a)>0.1)
mean(abs(a)>0.9)
mean(abs(a)>0.8)
sum(abs(a)>0.8)
sum(abs(a)>0.7)-
sum(abs(a)>0.7)
sum((a)>0.7)
sum((a)>0.8)
sum(abs(a)>0.8)
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/thier.R')
library(fpp2)
library(hts)
library(thief)
source("hier.R")
source('~/switchDrive/hierTs/hierarchicalTimeSeries/code/hierTs/batchM3.R')
library(Mcomp)
type="monthly"
M3.selected <- subset(M3,12)
i<-1
tsObj<-M3.selected[[i]]
fmethod
fmethod<-"ets"
periodType<-type
#computes mae for temporal hierarchies
#both actual and forecast are temporal hierarchies
#it  averages the  different time series having the same frequency
getHierMae <- function (actual, forecast) {
hierMae <- vector(length = length(forecast))
for (i in seq_along(forecast)) {
hierMae[i] <- mean( abs (forecast[[i]]$mean - actual[[i]]) )
}
return (hierMae)
}
globalMse <- function (actual, forecast) {
mse <- 0
for (i in seq_along(forecast)) {
mse <- mse + sum ( (forecast[[i]]$mean - actual[[i]])^2 )
}
return (mse)
}
calibration <- function (actual, forecast, sigmas) {
included50 <- as.vector(rep(0,length(actual)))
included80 <- as.vector(rep(0,length(actual)))
#implementation to be finalized
for (ii in seq_along(forecast)) {
upper50 <- as.numeric(fc[[i]]$upper[,"50%"])
lower50 <- as.numeric(fc[[i]]$lower[,"50%"])
included50[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
upper80 <- as.numeric(fc[[i]]$upper[,"80%"])
lower80 <- as.numeric(fc[[i]]$lower[,"80%"])
included80[ii] <- (actual[ii] > lower) &  (actual[ii] < upper)
}
return (mean(included50),mean(included80))
}
#builds the A matrix, which indicates  which bottom time series sum up to each upper time series.
buildMatrix <- function() {
A <- matrix(data = 0, nrow = length(upperIdx), ncol = length(bottomIdx))
maxFreq <- frequency(trainHier[[1]])
counter <- 1
for (ii in (2:length(trainHier))){
currentFreq <- frequency(trainHier[[ii]])
aggregatedTs <- currentFreq
howManyBottomToSum <- maxFreq / currentFreq
offset <- 1
for (jj in (1:aggregatedTs)) {
A[counter, offset : (offset + howManyBottomToSum - 1)] <- 1
offset <- offset + howManyBottomToSum
counter <- counter + 1
}
return (t(A))
}
#coverage of the PI is 0.8
alpha <- 0.2
#default test set for the M3 is 18 months for the monthly (tp be adapted) and 8 quarters for the quarterly.
#for the moment force the test to be as long as exactly one period
#we should implement a mechanism for doing repeated predictions
train <- tsObj$x
trainHier <- tsaggregates(train)
timeIdx <- time(tsObj$xx)
test <- window(tsObj$xx, end=timeIdx[frequency(tsObj$xx)])
testHier <- tsaggregates(test)
# Compute forecasts one full season ahead
fc <- list()
#how many test observations are available
h=length(testHier[[i]])
# fc[[i]] <- forecast(ets(trainHier[[i]]), h=h, level = (1-alpha), additive.only = TRUE)
fc[[i]] <- forecast(ets(trainHier[[i]]), h=h, level = c(0.5,0.8), additive.only = TRUE)
# Reconcile forecasts using thief
thiefReconc <- reconcilethief(fc, comb = "struc")
for(i in seq_along(trainHier)){
#how many test observations are available
h=length(testHier[[i]])
if (fmethod == "ets") {
# fc[[i]] <- forecast(ets(trainHier[[i]]), h=h, level = (1-alpha), additive.only = TRUE)
fc[[i]] <- forecast(ets(trainHier[[i]]), h=h, level = c(0.5,0.8), additive.only = TRUE)
}
else if (fmethod == "arima") {
fc[[i]] <- forecast(auto.arima(trainHier[[i]]), h=h, , level = (1-alpha))
}
# Reconcile forecasts using thief
thiefReconc <- reconcilethief(fc, comb = "struc")
buReconc <- reconcilethief(fc, comb = "bu")
#default test set for the M3 is 18 months for the monthly (tp be adapted) and 8 quarters for the quarterly.
#for the moment force the test to be as long as exactly one period
#we should implement a mechanism for doing repeated predictions
train <- tsObj$x
trainHier <- tsaggregates(train)
timeIdx <- time(tsObj$xx)
test <- window(tsObj$xx, end=timeIdx[frequency(tsObj$xx)])
testHier <- tsaggregates(test)
# Compute forecasts one full season ahead
fc <- list()
for(i in seq_along(trainHier)){
#how many test observations are available
h=length(testHier[[i]])
if (fmethod == "ets") {
# fc[[i]] <- forecast(ets(trainHier[[i]]), h=h, level = (1-alpha), additive.only = TRUE)
fc[[i]] <- forecast(ets(trainHier[[i]]), h=h, level = c(0.5,0.8), additive.only = TRUE)
}
else if (fmethod == "arima") {
fc[[i]] <- forecast(auto.arima(trainHier[[i]]), h=h, , level = (1-alpha))
}
# Reconcile forecasts using thief
thiefReconc <- reconcilethief(fc, comb = "struc")
buReconc <- reconcilethief(fc, comb = "bu")
thiefReconc
buReconc
globalMse(testHier, thiefReconc)
globalMse(testHier, buReconc)
thiefReconc2 <- reconcilethief(fc, comb = "struc")
?reconcilethief
thiefReconc2 <- reconcilethief(fc, comb = "mse")
library(Mcomp)
source("thier.R")
type="monthly"
fmethod="ets"
M3.selected <- subset(M3,12)
i<-2
print(M3.selected[[i]]$sn)
thier(M3.selected[[i]],fmethod=fmethod, periodType=type)
thiefReconc2 <- reconcilethief(fc, comb = "mse")
globalMse(testHier, thiefReconc)
globalMse(testHier, bayesReconc)
thiefReconc2 <- reconcilethief(fc, comb = "mse")
